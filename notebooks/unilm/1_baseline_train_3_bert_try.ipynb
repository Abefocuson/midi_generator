{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastai.text import *\n",
    "from enum import Enum\n",
    "import torch\n",
    "from fastai.text.models.awd_lstm import *\n",
    "from fastai.text.models.transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(edgeitems=10, threshold=40, linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../')\n",
    "from src.fastai_data import *\n",
    "from src.encode_data import *\n",
    "from src.serve import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lmnp_transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../../data/midi/v14/piano_duet/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Stream Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ctx_len': 150,\n",
       " 'n_layers': 16,\n",
       " 'n_heads': 8,\n",
       " 'd_model': 256,\n",
       " 'd_head': 32,\n",
       " 'd_inner': 2048,\n",
       " 'resid_p': 0.1,\n",
       " 'attn_p': 0.1,\n",
       " 'ff_p': 0.1,\n",
       " 'embed_p': 0.1,\n",
       " 'output_p': 0.1,\n",
       " 'bias': False,\n",
       " 'scale': True,\n",
       " 'act': <Activation.GeLU: 3>,\n",
       " 'double_drop': True,\n",
       " 'tie_weights': True,\n",
       " 'out_bias': True,\n",
       " 'init': <function fastai.text.models.transformer.init_transformer(m)>,\n",
       " 'mem_len': 512,\n",
       " 'mask': True,\n",
       " 'pad_idx': 1,\n",
       " 'bos_idx': 0,\n",
       " 'sep_idx': 8,\n",
       " 'transpose_range': (0, 12),\n",
       " 'note_range': (9, 138),\n",
       " 'bs': 16,\n",
       " 'bptt': 256,\n",
       " 'vocab_size': 274}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = v14s_config(vocab); config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fastai Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_tfms = [mask_tfm, next_sentence_tfm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLTFMS: [<function mask_tfm at 0x7f22600c6620>, <function next_sentence_tfm at 0x7f22600c6598>]\n"
     ]
    }
   ],
   "source": [
    "data = load_music_data(path, cache_name='tmp/sample', vocab=vocab, y_offset=0, dl_tfms=dl_tfms, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb,yb = data.one_batch(cpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[141,   8, 141,  ...,  96, 143,  86],\n",
       "        [141,   8, 141,  ...,  94, 143,  84],\n",
       "        [141,   8, 141,  ...,  99, 143,  89],\n",
       "        ...,\n",
       "        [141,   8, 141,  ...,  96, 143,  86],\n",
       "        [141,   8, 141,  ...,  95, 143,  85],\n",
       "        [  4,   8, 141,  ...,  96, 143,  86]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[  1,   1,   1,  ...,   1,   1,   1],\n",
       "         [  1,   1,   1,  ...,   1,   1,   1],\n",
       "         [  1,   1,   1,  ...,   1,   1,   1],\n",
       "         ...,\n",
       "         [  1,   1,   1,  ...,   1,   1,   1],\n",
       "         [  1,   1,   1,  ...,   1,   1,   1],\n",
       "         [141,   1,   1,  ...,   1,   1,   1]], device='cuda:0'),\n",
       " tensor([[0, 0, 0,  ..., 2, 2, 2],\n",
       "         [0, 0, 0,  ..., 2, 2, 2],\n",
       "         [0, 0, 0,  ..., 2, 2, 2],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 2, 2, 2],\n",
       "         [0, 0, 0,  ..., 2, 2, 2],\n",
       "         [0, 0, 0,  ..., 2, 2, 2]], device='cuda:0')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LMNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_len = 0\n",
    "# x_len = 16 # bptt\n",
    "# seq_len = m_len+x_len\n",
    "# torch.triu(torch.ones(x_len, seq_len), diagonal=m_len).byte()[None,None].cpu().numpy()\n",
    "# torch.triu(torch.ones(x_len, seq_len), diagonal=m_len+1).byte()[None,None].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicAttention(MultiHeadRelativeAttention):\n",
    "    def __init__(self, n_heads:int, d_model:int, d_head:int, resid_p:float=0., attn_p:float=0., bias:bool=True,\n",
    "                 scale:bool=True, residual:bool=True):\n",
    "        super().__init__(n_heads, d_model, d_head, resid_p=resid_p, attn_p=attn_p, bias=bias, scale=scale)\n",
    "        self.residual = residual\n",
    "        \n",
    "    def forward(self, x:Tensor, mask:Tensor=None, **kwargs):\n",
    "        if self.residual: return self.ln(x + self.drop_res(self.out(self._apply_attention(x, mask=mask, **kwargs))))\n",
    "        return self.ln(self.drop_res(self.out(self._apply_attention(x, mask=mask, **kwargs))))\n",
    "    \n",
    "class MusicTransformerXL(nn.Module):\n",
    "    \"TransformerXL model: https://arxiv.org/abs/1901.02860.\"\n",
    "    def __init__(self, vocab_sz:int, ctx_len:int, n_layers:int, n_heads:int, d_model:int, d_head:int, d_inner:int, \n",
    "                 resid_p:float=0., attn_p:float=0., ff_p:float=0., embed_p:float=0., bias:bool=False, scale:bool=True,\n",
    "                 act:Activation=Activation.ReLU, double_drop:bool=True, attn_cls:Callable=MusicAttention,\n",
    "                 learned_pos_enc:bool=False, mask:bool=True, mem_len:int=0, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Embedding(vocab_sz, d_model)\n",
    "        self.pos_enc = nn.Embedding(ctx_len, d_model) if learned_pos_enc else PositionalEncoding(d_model)\n",
    "        self.drop_emb = nn.Dropout(embed_p)\n",
    "        self.u = nn.Parameter(torch.Tensor(n_heads, 1, d_head)) #Remove 1 for einsum implementation of attention\n",
    "        self.v = nn.Parameter(torch.Tensor(n_heads, 1, d_head)) #Remove 1 for einsum implementation of attention\n",
    "        self.mem_len,self.n_layers,self.d_model,self.mask = mem_len,n_layers,d_model,mask\n",
    "        self.init = False\n",
    "        self.layers = nn.ModuleList([DecoderLayer(n_heads, d_model, d_head, d_inner, resid_p=resid_p, attn_p=attn_p,\n",
    "                      ff_p=ff_p, bias=bias, scale=scale, act=act, double_drop=double_drop, \n",
    "                      attn_cls=attn_cls) for k in range(n_layers)])\n",
    "#         self.layers[0].mhra.residual = False\n",
    "    \n",
    "    def reset(self):\n",
    "        \"Reset the internal memory.\"\n",
    "        self.hidden = [next(self.parameters()).data.new(0) for i in range(self.n_layers+1)]\n",
    "\n",
    "    def _update_mems(self, hids):\n",
    "        if not getattr(self, 'hidden', False): return None\n",
    "        assert len(hids) == len(self.hidden), 'len(hids) != len(self.hidden)'\n",
    "        with torch.no_grad():\n",
    "            for i in range(len(hids)):\n",
    "                cat = torch.cat([self.hidden[i], hids[i]], dim=1)\n",
    "                self.hidden[i] = cat[:,-self.mem_len:].detach()\n",
    "    \n",
    "    def select_hidden(self, idxs): self.hidden = [h[idxs] for h in self.hidden]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #The hidden state has to be initiliazed in the forward pass for nn.DataParallel\n",
    "        if self.mem_len > 0 and not self.init: \n",
    "            self.reset()\n",
    "            self.init = True\n",
    "        bs,x_len = x.size()\n",
    "        inp = self.drop_emb(self.encoder(x)) #.mul_(self.d_model ** 0.5)\n",
    "        m_len = self.hidden[0].size(1) if hasattr(self, 'hidden') and len(self.hidden[0].size()) > 1 else 0\n",
    "        seq_len = m_len + x_len\n",
    "#         mask = torch.triu(x.new_ones(x_len, seq_len), diagonal=m_len+1).byte()[None,None] if self.mask else None\n",
    "        mask = torch.triu(x.new_ones(x_len, seq_len), diagonal=m_len).byte()[None,None] if self.mask else None\n",
    "        if m_len == 0 and self.mask: mask[0,0] = 0\n",
    "        #[None,:,:None] for einsum implementation of attention\n",
    "        hids = []\n",
    "        pos = torch.arange(seq_len-1, -1, -1, device=inp.device, dtype=inp.dtype)\n",
    "        pos_enc = self.pos_enc(pos)\n",
    "        hids.append(inp)\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            mem = self.hidden[i] if self.mem_len > 0 else None\n",
    "            inp = layer(inp, r=pos_enc, u=self.u, v=self.v, mask=mask, mem=mem)\n",
    "            hids.append(inp)\n",
    "        core_out = inp[:,-x_len:]\n",
    "        if self.mem_len > 0 : self._update_mems(hids)\n",
    "        return (self.hidden if self.mem_len > 0 else [core_out]),[core_out]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.model[0].layers[0].mhra.residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.learner import _model_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['mem_len'] = 0\n",
    "config['mask'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ctx_len': 150,\n",
       " 'n_layers': 16,\n",
       " 'n_heads': 8,\n",
       " 'd_model': 256,\n",
       " 'd_head': 32,\n",
       " 'd_inner': 2048,\n",
       " 'resid_p': 0.1,\n",
       " 'attn_p': 0.1,\n",
       " 'ff_p': 0.1,\n",
       " 'embed_p': 0.1,\n",
       " 'output_p': 0.1,\n",
       " 'bias': False,\n",
       " 'scale': True,\n",
       " 'act': <Activation.GeLU: 3>,\n",
       " 'double_drop': True,\n",
       " 'tie_weights': True,\n",
       " 'out_bias': True,\n",
       " 'init': <function fastai.text.models.transformer.init_transformer(m)>,\n",
       " 'mem_len': 0,\n",
       " 'mask': False,\n",
       " 'pad_idx': 1,\n",
       " 'bos_idx': 0,\n",
       " 'sep_idx': 8,\n",
       " 'transpose_range': (0, 12),\n",
       " 'note_range': (9, 138),\n",
       " 'bs': 16,\n",
       " 'bptt': 256,\n",
       " 'vocab_size': 274}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_model_meta[MusicTransformerXL] = _model_meta[TransformerXL]\n",
    "_model_meta[MusicTransformerXL]['config_lm'] = config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LinearDecoder(nn.Module):\n",
    "    \"To go on top of a RNNCore module and create a Language Model.\"\n",
    "    initrange=0.1\n",
    "\n",
    "    def __init__(self, n_out:int, n_hid:int, output_p:float, tie_encoder:nn.Module=None, bias:bool=True):\n",
    "        super().__init__()\n",
    "        self.decoder = nn.Linear(n_hid, n_out, bias=bias)\n",
    "        self.decoder.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.output_dp = RNNDropout(output_p)\n",
    "        if bias: self.decoder.bias.data.zero_()\n",
    "        if tie_encoder: self.decoder.weight = tie_encoder.weight\n",
    "\n",
    "    def forward(self, input:Tuple[Tensor,Tensor])->Tuple[Tensor,Tensor,Tensor]:\n",
    "        raw_outputs, outputs = input\n",
    "        output = self.output_dp(outputs[-1])\n",
    "        decoded = self.decoder(output)\n",
    "        return decoded, raw_outputs, outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertHead(nn.Module):\n",
    "    def __init__(self, encoder, decoder, ns_decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.ns_decoder = ns_decoder\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_e = self.encoder(x)\n",
    "        return self.decoder(x_e), self.ns_decoder(x_e)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return [self.encoder, self.decoder, self.ns_decoder][idx]\n",
    "        \n",
    "    \"A sequential module that passes the reset call to its children.\"\n",
    "    def reset(self):\n",
    "        for c in [self.encoder, self.decoder, self.ns_decoder]:\n",
    "            if hasattr(c, 'reset'): c.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NSDecoder(nn.Module):\n",
    "    \"To go on top of a RNNCore module and create a Language Model.\"\n",
    "    initrange=0.1\n",
    "\n",
    "    def __init__(self, n_out:int, n_hid:int, bias:bool=True):\n",
    "        super().__init__()\n",
    "        self.decoder = nn.Linear(n_hid, n_out, bias=bias)\n",
    "        self.decoder.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        if bias: self.decoder.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input:Tuple[Tensor,Tensor])->Tuple[Tensor,Tensor,Tensor]:\n",
    "        raw_outputs, outputs = input\n",
    "        decoded = self.decoder(outputs[-1])\n",
    "        return decoded, raw_outputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_music_model(arch:Callable, vocab_sz:int, config:dict=None, drop_mult:float=1.):\n",
    "    \"Create a language model from `arch` and its `config`, maybe `pretrained`.\"\n",
    "    meta = _model_meta[arch]\n",
    "    config = ifnone(config, meta['config_lm'].copy())\n",
    "    for k in config.keys(): \n",
    "        if k.endswith('_p'): config[k] *= drop_mult\n",
    "#     tie_weights,output_p,out_bias = map(config.pop, ['tie_weights', 'output_p', 'out_bias'])\n",
    "    tie_weights,output_p,out_bias = map(config.get, ['tie_weights', 'output_p', 'out_bias'])\n",
    "    init = config.pop('init') if 'init' in config else None\n",
    "    encoder = arch(vocab_sz, **config)\n",
    "    enc = encoder.encoder if tie_weights else None\n",
    "    decoder = LinearDecoder(vocab_sz, config[meta['hid_name']], output_p, tie_encoder=enc, bias=out_bias)\n",
    "    ns_decoder = NSDecoder(4, config[meta['hid_name']])\n",
    "    model = BertHead(encoder, decoder, ns_decoder)\n",
    "    return model if init is None else model.apply(init)\n",
    "\n",
    "\n",
    "def music_model_learner(arch:Callable, data:DataBunch, config:dict=None, drop_mult:float=1., pretrained:bool=False,\n",
    "                        pretrained_fnames:OptStrTuple=None, **learn_kwargs) -> 'LanguageLearner':\n",
    "    \"Create a `Learner` with a language model from `data` and `arch`.\"\n",
    "    model = get_music_model(arch, config['vocab_size'], config=config, drop_mult=drop_mult)\n",
    "    \n",
    "    meta = _model_meta[arch]\n",
    "    learn = MusicLearner(data, model, split_func=meta['split_lm'], \n",
    "                         bos_idx=config['bos_idx'], sep_idx=config['sep_idx'],\n",
    "                        **learn_kwargs)\n",
    "    \n",
    "    if pretrained:\n",
    "        if 'url' not in meta: \n",
    "            warn(\"There are no pretrained weights for that architecture yet!\")\n",
    "            return learn\n",
    "        model_path = untar_data(meta['url'], data=False)\n",
    "        fnames = [list(model_path.glob(f'*.{ext}'))[0] for ext in ['pth', 'pkl']]\n",
    "        learn.load_pretrained(*fnames)\n",
    "        learn.freeze()\n",
    "    if pretrained_fnames is not None:\n",
    "        fnames = [learn.path/learn.model_dir/f'{fn}.{ext}' for fn,ext in zip(pretrained_fnames, ['pth', 'pkl'])]\n",
    "        learn.load_pretrained(*fnames)\n",
    "        learn.freeze()\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sep_idx: 8\n"
     ]
    }
   ],
   "source": [
    "learn = music_model_learner(MusicTransformerXL, data, config, drop_mult=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb,yb = data.one_batch(cpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLoss():\n",
    "    def __init__(self, mask_loss, sent_loss):\n",
    "        self.mask_loss = mask_loss\n",
    "        self.sent_loss = sent_loss\n",
    "        \n",
    "    def __call__(self, input:Tensor, target:Tensor, target_sen:Tensor, **kwargs)->Rank0Tensor:\n",
    "        m = self.mask_loss.__call__(input[0], target, **kwargs)\n",
    "        s = self.sent_loss.__call__(input[1], target_sen, **kwargs)\n",
    "        return m + s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks.rnn import RNNTrainer\n",
    "class BertRNNTrainer(RNNTrainer):\n",
    "    \"`Callback` that regroups lr adjustment to seq_len, AR and TAR.\"\n",
    "    def __init__(self, learn:Learner, alpha:float=0., beta:float=0.):\n",
    "        super().__init__(learn, alpha, beta)\n",
    "        \n",
    "#     def on_epoch_begin(self, **kwargs):\n",
    "#         \"Reset the hidden state of the model.\"\n",
    "#         self.learn.model.reset()\n",
    "\n",
    "    def on_loss_begin(self, last_output:Tuple[Tensor,Tensor,Tensor], **kwargs):\n",
    "        \"Save the extra outputs for later and only returns the true output.\"\n",
    "        return super().on_loss_begin(last_output[0])\n",
    "#         self.raw_out,self.out = last_output[1],last_output[2]\n",
    "#         return {'last_output': last_output[0]}\n",
    "\n",
    "#     def on_backward_begin(self, last_loss:Rank0Tensor, last_input:Tensor, **kwargs):\n",
    "#         \"Apply AR and TAR to `last_loss`.\"\n",
    "#         #AR and TAR\n",
    "#         if self.alpha != 0.:  last_loss += self.alpha * self.out[-1].float().pow(2).mean()\n",
    "#         if self.beta != 0.:\n",
    "#             h = self.raw_out[-1]\n",
    "#             if len(h)>1: last_loss += self.beta * (h[:,1:] - h[:,:-1]).float().pow(2).mean()\n",
    "#         return {'last_loss': last_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertTrainer(LearnerCallback):\n",
    "    \"`Callback` that regroups lr adjustment to seq_len, AR and TAR.\"\n",
    "    def __init__(self, learn:Learner):\n",
    "        super().__init__(learn)\n",
    "        \n",
    "    def on_loss_begin(self, last_output:Tuple[Tensor,Tensor,Tensor], **kwargs):\n",
    "        \"Save the extra outputs for later and only returns the true output.\"\n",
    "        return {'last_output': (last_output[0][0], last_output[1][0]) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(learn.callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.callbacks = [BertTrainer(learn, alpha=2, beta=1)]\n",
    "learn.callbacks = [BertTrainer(learn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func = BertLoss(CrossEntropyFlat(ignore_index=vocab.pad_idx), CrossEntropyFlat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[[ 0.0960,  0.7304,  0.5870,  ..., -0.3558, -0.0351,  0.1293],\n",
       "           [ 0.0330, -0.2509,  0.1509,  ...,  0.1848,  0.1848, -0.1398],\n",
       "           [-0.3860,  0.5528,  0.1872,  ...,  0.0809,  0.3503,  0.1579],\n",
       "           ...,\n",
       "           [ 0.1481, -0.5409, -0.2819,  ..., -0.4559,  0.2345, -0.4213],\n",
       "           [ 0.1694, -0.2258, -0.7146,  ..., -0.0030, -0.1551, -0.2437],\n",
       "           [-0.3028, -0.4687, -0.1243,  ..., -0.4610, -0.1998,  0.1170]],\n",
       "  \n",
       "          [[ 0.1549, -0.5216, -0.2756,  ..., -0.4585,  0.2363, -0.4137],\n",
       "           [ 0.0422, -0.2308,  0.1545,  ...,  0.1814,  0.1888, -0.1338],\n",
       "           [ 0.3883,  0.0983,  0.1274,  ..., -0.6362,  0.3298, -0.1741],\n",
       "           ...,\n",
       "           [ 0.1551, -0.5209, -0.2770,  ..., -0.4577,  0.2364, -0.4144],\n",
       "           [-0.0859,  0.2476, -0.3591,  ...,  0.1663, -0.0769,  0.4624],\n",
       "           [-0.2974, -0.4600, -0.1151,  ..., -0.4643, -0.1916,  0.1223]],\n",
       "  \n",
       "          [[-0.0865, -0.0054,  0.1733,  ...,  0.0117, -0.1034, -0.3831],\n",
       "           [ 0.0430, -0.2598,  0.1512,  ...,  0.1844,  0.1873, -0.1362],\n",
       "           [ 0.1543, -0.5477, -0.2814,  ..., -0.4553,  0.2339, -0.4140],\n",
       "           ...,\n",
       "           [-0.2939, -0.4827, -0.1255,  ..., -0.4603, -0.1957,  0.1214],\n",
       "           [ 0.1794, -0.2339, -0.7140,  ..., -0.0052, -0.1530, -0.2333],\n",
       "           [ 0.1541, -0.5473, -0.2817,  ..., -0.4550,  0.2349, -0.4150]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 0.0977,  0.7319,  0.5849,  ..., -0.3537, -0.0363,  0.1307],\n",
       "           [ 0.0362, -0.2476,  0.1491,  ...,  0.1869,  0.1825, -0.1400],\n",
       "           [-0.3841,  0.5580,  0.1865,  ...,  0.0820,  0.3478,  0.1601],\n",
       "           ...,\n",
       "           [-0.2989, -0.4650, -0.1231,  ..., -0.4589, -0.1993,  0.1171],\n",
       "           [ 0.2430, -0.0752,  0.0198,  ...,  0.1562, -0.0039,  0.7171],\n",
       "           [-0.1382,  0.2563, -0.3992,  ...,  0.1728, -0.0785,  0.1408]],\n",
       "  \n",
       "          [[ 0.1457, -0.5315, -0.2834,  ..., -0.4566,  0.2245, -0.4180],\n",
       "           [ 0.1460, -0.5310, -0.2825,  ..., -0.4573,  0.2242, -0.4175],\n",
       "           [-0.0414,  0.1920,  0.1740,  ..., -0.1255,  0.0869,  0.3648],\n",
       "           ...,\n",
       "           [-0.3028, -0.4645, -0.1246,  ..., -0.4618, -0.2016,  0.1162],\n",
       "           [ 0.1724, -0.2190, -0.7157,  ..., -0.0035, -0.1650, -0.2354],\n",
       "           [ 0.1454, -0.5316, -0.2834,  ..., -0.4566,  0.2245, -0.4180]],\n",
       "  \n",
       "          [[ 0.0857,  0.1622,  0.1975,  ...,  0.6916,  0.0823,  0.1548],\n",
       "           [ 0.0350, -0.2382,  0.1449,  ...,  0.1871,  0.1888, -0.1318],\n",
       "           [ 0.2519, -0.3086, -0.2322,  ...,  0.1881,  0.2404,  0.5058],\n",
       "           ...,\n",
       "           [-0.3043, -0.4559, -0.1270,  ..., -0.4658, -0.1915,  0.1305],\n",
       "           [-0.1479,  0.2352,  0.1122,  ...,  0.2089,  0.5334,  0.4692],\n",
       "           [-0.3048, -0.4564, -0.1271,  ..., -0.4657, -0.1917,  0.1305]]],\n",
       "         device='cuda:0', grad_fn=<AddBackward0>),\n",
       "  [tensor([[[ 1.3394,  0.0085, -2.3403,  ..., -1.6764, -0.7550,  1.4601],\n",
       "            [ 0.0717, -1.8042, -0.1034,  ..., -0.7903,  0.0620, -0.4240],\n",
       "            [ 0.1376, -0.2631,  0.8937,  ...,  1.0681,  1.6646, -0.3793],\n",
       "            ...,\n",
       "            [ 0.0441, -0.8707, -0.2556,  ..., -1.8257,  0.0604,  0.0659],\n",
       "            [-1.0251, -1.2553, -0.1618,  ...,  0.3193, -0.8039, -0.4302],\n",
       "            [ 0.1309,  0.3416, -0.1560,  ...,  0.7763,  0.7859, -0.9291]],\n",
       "   \n",
       "           [[ 0.0480, -0.9066, -0.2707,  ..., -1.8152,  0.0511,  0.0643],\n",
       "            [ 0.0762, -1.8434, -0.1031,  ..., -0.7839,  0.0424, -0.4289],\n",
       "            [-0.0928, -0.5924,  0.5868,  ...,  0.5230, -0.5770, -0.3946],\n",
       "            ...,\n",
       "            [ 0.0476, -0.9058, -0.2699,  ..., -1.8186,  0.0542,  0.0646],\n",
       "            [ 0.4381, -2.0509, -2.1245,  ..., -0.9334, -0.5901, -0.0810],\n",
       "            [ 0.1525,  0.2925, -0.1801,  ...,  0.7772,  0.7675, -0.9354]],\n",
       "   \n",
       "           [[ 0.4387, -0.9227, -0.3280,  ...,  1.4953, -0.4532, -0.3426],\n",
       "            [ 0.0431, -1.8318, -0.1203,  ..., -0.8069,  0.0244, -0.4532],\n",
       "            [ 0.0261, -0.8947, -0.2701,  ..., -1.8429,  0.0357,  0.0322],\n",
       "            ...,\n",
       "            [ 0.1267,  0.3105, -0.1661,  ...,  0.7486,  0.7539, -0.9609],\n",
       "            [-1.0525, -1.2835, -0.1608,  ...,  0.2912, -0.8315, -0.4540],\n",
       "            [ 0.0262, -0.8940, -0.2700,  ..., -1.8415,  0.0337,  0.0327]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[ 1.3542, -0.0265, -2.3524,  ..., -1.6769, -0.7775,  1.4682],\n",
       "            [ 0.0754, -1.8394, -0.1158,  ..., -0.7906,  0.0319, -0.4042],\n",
       "            [ 0.1518, -0.3014,  0.8851,  ...,  1.0678,  1.6437, -0.3611],\n",
       "            ...,\n",
       "            [ 0.1472,  0.3016, -0.1778,  ...,  0.7679,  0.7643, -0.9142],\n",
       "            [-1.8668,  1.6955,  1.8174,  ...,  1.2129,  0.6638, -1.5788],\n",
       "            [-0.9747, -0.9389,  0.0660,  ..., -0.7179, -0.9565, -0.1753]],\n",
       "   \n",
       "           [[ 0.0544, -0.8538, -0.2660,  ..., -1.8658,  0.1091,  0.0493],\n",
       "            [ 0.0515, -0.8535, -0.2666,  ..., -1.8648,  0.1083,  0.0518],\n",
       "            [ 1.4296, -0.7718, -0.5383,  ..., -1.5112, -0.6193,  0.2453],\n",
       "            ...,\n",
       "            [ 0.1553,  0.3473, -0.1562,  ...,  0.7278,  0.8237, -0.9463],\n",
       "            [-1.0250, -1.2593, -0.1540,  ...,  0.2617, -0.7727, -0.4403],\n",
       "            [ 0.0536, -0.8538, -0.2657,  ..., -1.8658,  0.1091,  0.0502]],\n",
       "   \n",
       "           [[ 1.0861, -0.7966, -0.0279,  ..., -1.0644, -1.9882, -2.0222],\n",
       "            [ 0.0332, -1.7696, -0.0760,  ..., -0.8386,  0.0382, -0.3731],\n",
       "            [ 1.5431, -0.3382,  2.3350,  ...,  1.7097,  0.7026, -0.5838],\n",
       "            ...,\n",
       "            [ 0.1058,  0.3848, -0.1312,  ...,  0.7278,  0.7726, -0.8798],\n",
       "            [ 0.2289,  1.2111,  0.3276,  ..., -0.1416,  0.0493, -0.3878],\n",
       "            [ 0.1065,  0.3839, -0.1312,  ...,  0.7286,  0.7737, -0.8796]]],\n",
       "          device='cuda:0', grad_fn=<SliceBackward>)],\n",
       "  [tensor([[[ 1.3394,  0.0085, -2.3403,  ..., -1.6764, -0.7550,  1.4601],\n",
       "            [ 0.0717, -1.8042, -0.1034,  ..., -0.7903,  0.0620, -0.4240],\n",
       "            [ 0.1376, -0.2631,  0.8937,  ...,  1.0681,  1.6646, -0.3793],\n",
       "            ...,\n",
       "            [ 0.0441, -0.8707, -0.2556,  ..., -1.8257,  0.0604,  0.0659],\n",
       "            [-1.0251, -1.2553, -0.1618,  ...,  0.3193, -0.8039, -0.4302],\n",
       "            [ 0.1309,  0.3416, -0.1560,  ...,  0.7763,  0.7859, -0.9291]],\n",
       "   \n",
       "           [[ 0.0480, -0.9066, -0.2707,  ..., -1.8152,  0.0511,  0.0643],\n",
       "            [ 0.0762, -1.8434, -0.1031,  ..., -0.7839,  0.0424, -0.4289],\n",
       "            [-0.0928, -0.5924,  0.5868,  ...,  0.5230, -0.5770, -0.3946],\n",
       "            ...,\n",
       "            [ 0.0476, -0.9058, -0.2699,  ..., -1.8186,  0.0542,  0.0646],\n",
       "            [ 0.4381, -2.0509, -2.1245,  ..., -0.9334, -0.5901, -0.0810],\n",
       "            [ 0.1525,  0.2925, -0.1801,  ...,  0.7772,  0.7675, -0.9354]],\n",
       "   \n",
       "           [[ 0.4387, -0.9227, -0.3280,  ...,  1.4953, -0.4532, -0.3426],\n",
       "            [ 0.0431, -1.8318, -0.1203,  ..., -0.8069,  0.0244, -0.4532],\n",
       "            [ 0.0261, -0.8947, -0.2701,  ..., -1.8429,  0.0357,  0.0322],\n",
       "            ...,\n",
       "            [ 0.1267,  0.3105, -0.1661,  ...,  0.7486,  0.7539, -0.9609],\n",
       "            [-1.0525, -1.2835, -0.1608,  ...,  0.2912, -0.8315, -0.4540],\n",
       "            [ 0.0262, -0.8940, -0.2700,  ..., -1.8415,  0.0337,  0.0327]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[ 1.3542, -0.0265, -2.3524,  ..., -1.6769, -0.7775,  1.4682],\n",
       "            [ 0.0754, -1.8394, -0.1158,  ..., -0.7906,  0.0319, -0.4042],\n",
       "            [ 0.1518, -0.3014,  0.8851,  ...,  1.0678,  1.6437, -0.3611],\n",
       "            ...,\n",
       "            [ 0.1472,  0.3016, -0.1778,  ...,  0.7679,  0.7643, -0.9142],\n",
       "            [-1.8668,  1.6955,  1.8174,  ...,  1.2129,  0.6638, -1.5788],\n",
       "            [-0.9747, -0.9389,  0.0660,  ..., -0.7179, -0.9565, -0.1753]],\n",
       "   \n",
       "           [[ 0.0544, -0.8538, -0.2660,  ..., -1.8658,  0.1091,  0.0493],\n",
       "            [ 0.0515, -0.8535, -0.2666,  ..., -1.8648,  0.1083,  0.0518],\n",
       "            [ 1.4296, -0.7718, -0.5383,  ..., -1.5112, -0.6193,  0.2453],\n",
       "            ...,\n",
       "            [ 0.1553,  0.3473, -0.1562,  ...,  0.7278,  0.8237, -0.9463],\n",
       "            [-1.0250, -1.2593, -0.1540,  ...,  0.2617, -0.7727, -0.4403],\n",
       "            [ 0.0536, -0.8538, -0.2657,  ..., -1.8658,  0.1091,  0.0502]],\n",
       "   \n",
       "           [[ 1.0861, -0.7966, -0.0279,  ..., -1.0644, -1.9882, -2.0222],\n",
       "            [ 0.0332, -1.7696, -0.0760,  ..., -0.8386,  0.0382, -0.3731],\n",
       "            [ 1.5431, -0.3382,  2.3350,  ...,  1.7097,  0.7026, -0.5838],\n",
       "            ...,\n",
       "            [ 0.1058,  0.3848, -0.1312,  ...,  0.7278,  0.7726, -0.8798],\n",
       "            [ 0.2289,  1.2111,  0.3276,  ..., -0.1416,  0.0493, -0.3878],\n",
       "            [ 0.1065,  0.3839, -0.1312,  ...,  0.7286,  0.7737, -0.8796]]],\n",
       "          device='cuda:0', grad_fn=<SliceBackward>)]),\n",
       " (tensor([[[ 0.0376, -0.2435,  0.2531, -0.4234],\n",
       "           [ 0.0357, -0.2344, -0.0920, -0.3562],\n",
       "           [-0.0814, -0.1157,  0.0036, -0.2747],\n",
       "           ...,\n",
       "           [ 0.3704,  0.9773,  0.4464, -0.3554],\n",
       "           [ 0.0958, -0.0462,  0.3141, -0.4993],\n",
       "           [ 0.1399, -0.1574,  0.0292, -0.2700]],\n",
       "  \n",
       "          [[ 0.3665,  0.9601,  0.4479, -0.3492],\n",
       "           [ 0.0284, -0.2536, -0.0915, -0.3534],\n",
       "           [ 0.1510,  0.1240,  0.4280, -0.1024],\n",
       "           ...,\n",
       "           [ 0.3658,  0.9602,  0.4476, -0.3501],\n",
       "           [-0.3624,  0.1670,  0.0111, -0.1360],\n",
       "           [ 0.1334, -0.1734,  0.0311, -0.2662]],\n",
       "  \n",
       "          [[ 0.0640,  0.5394,  0.3395,  0.0692],\n",
       "           [ 0.0360, -0.2555, -0.0976, -0.3510],\n",
       "           [ 0.3702,  0.9600,  0.4432, -0.3485],\n",
       "           ...,\n",
       "           [ 0.1417, -0.1752,  0.0254, -0.2636],\n",
       "           [ 0.0924, -0.0635,  0.3067, -0.4922],\n",
       "           [ 0.3709,  0.9597,  0.4431, -0.3482]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 0.0343, -0.2490,  0.2532, -0.4217],\n",
       "           [ 0.0310, -0.2389, -0.0905, -0.3522],\n",
       "           [-0.0846, -0.1209,  0.0015, -0.2726],\n",
       "           ...,\n",
       "           [ 0.1353, -0.1611,  0.0310, -0.2652],\n",
       "           [-0.0682,  0.0805,  0.3158, -0.1756],\n",
       "           [ 0.1192, -0.6875,  0.0865, -0.0437]],\n",
       "  \n",
       "          [[ 0.3601,  0.9651,  0.4441, -0.3520],\n",
       "           [ 0.3602,  0.9650,  0.4437, -0.3519],\n",
       "           [ 0.1617,  0.2515,  0.1052, -0.0143],\n",
       "           ...,\n",
       "           [ 0.1314, -0.1640,  0.0295, -0.2674],\n",
       "           [ 0.0838, -0.0560,  0.3098, -0.4977],\n",
       "           [ 0.3606,  0.9650,  0.4439, -0.3521]],\n",
       "  \n",
       "          [[-0.0374,  0.5717,  0.4692,  0.0360],\n",
       "           [ 0.0181, -0.2466, -0.1043, -0.3580],\n",
       "           [-0.3782,  0.2030, -0.1375, -0.6303],\n",
       "           ...,\n",
       "           [ 0.1284, -0.1696,  0.0181, -0.2760],\n",
       "           [-0.2092, -0.3283, -0.0888,  0.0706],\n",
       "           [ 0.1286, -0.1697,  0.0183, -0.2762]]], device='cuda:0',\n",
       "         grad_fn=<AddBackward0>),\n",
       "  [tensor([[[ 1.3394,  0.0085, -2.3403,  ..., -1.6764, -0.7550,  1.4601],\n",
       "            [ 0.0717, -1.8042, -0.1034,  ..., -0.7903,  0.0620, -0.4240],\n",
       "            [ 0.1376, -0.2631,  0.8937,  ...,  1.0681,  1.6646, -0.3793],\n",
       "            ...,\n",
       "            [ 0.0441, -0.8707, -0.2556,  ..., -1.8257,  0.0604,  0.0659],\n",
       "            [-1.0251, -1.2553, -0.1618,  ...,  0.3193, -0.8039, -0.4302],\n",
       "            [ 0.1309,  0.3416, -0.1560,  ...,  0.7763,  0.7859, -0.9291]],\n",
       "   \n",
       "           [[ 0.0480, -0.9066, -0.2707,  ..., -1.8152,  0.0511,  0.0643],\n",
       "            [ 0.0762, -1.8434, -0.1031,  ..., -0.7839,  0.0424, -0.4289],\n",
       "            [-0.0928, -0.5924,  0.5868,  ...,  0.5230, -0.5770, -0.3946],\n",
       "            ...,\n",
       "            [ 0.0476, -0.9058, -0.2699,  ..., -1.8186,  0.0542,  0.0646],\n",
       "            [ 0.4381, -2.0509, -2.1245,  ..., -0.9334, -0.5901, -0.0810],\n",
       "            [ 0.1525,  0.2925, -0.1801,  ...,  0.7772,  0.7675, -0.9354]],\n",
       "   \n",
       "           [[ 0.4387, -0.9227, -0.3280,  ...,  1.4953, -0.4532, -0.3426],\n",
       "            [ 0.0431, -1.8318, -0.1203,  ..., -0.8069,  0.0244, -0.4532],\n",
       "            [ 0.0261, -0.8947, -0.2701,  ..., -1.8429,  0.0357,  0.0322],\n",
       "            ...,\n",
       "            [ 0.1267,  0.3105, -0.1661,  ...,  0.7486,  0.7539, -0.9609],\n",
       "            [-1.0525, -1.2835, -0.1608,  ...,  0.2912, -0.8315, -0.4540],\n",
       "            [ 0.0262, -0.8940, -0.2700,  ..., -1.8415,  0.0337,  0.0327]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[ 1.3542, -0.0265, -2.3524,  ..., -1.6769, -0.7775,  1.4682],\n",
       "            [ 0.0754, -1.8394, -0.1158,  ..., -0.7906,  0.0319, -0.4042],\n",
       "            [ 0.1518, -0.3014,  0.8851,  ...,  1.0678,  1.6437, -0.3611],\n",
       "            ...,\n",
       "            [ 0.1472,  0.3016, -0.1778,  ...,  0.7679,  0.7643, -0.9142],\n",
       "            [-1.8668,  1.6955,  1.8174,  ...,  1.2129,  0.6638, -1.5788],\n",
       "            [-0.9747, -0.9389,  0.0660,  ..., -0.7179, -0.9565, -0.1753]],\n",
       "   \n",
       "           [[ 0.0544, -0.8538, -0.2660,  ..., -1.8658,  0.1091,  0.0493],\n",
       "            [ 0.0515, -0.8535, -0.2666,  ..., -1.8648,  0.1083,  0.0518],\n",
       "            [ 1.4296, -0.7718, -0.5383,  ..., -1.5112, -0.6193,  0.2453],\n",
       "            ...,\n",
       "            [ 0.1553,  0.3473, -0.1562,  ...,  0.7278,  0.8237, -0.9463],\n",
       "            [-1.0250, -1.2593, -0.1540,  ...,  0.2617, -0.7727, -0.4403],\n",
       "            [ 0.0536, -0.8538, -0.2657,  ..., -1.8658,  0.1091,  0.0502]],\n",
       "   \n",
       "           [[ 1.0861, -0.7966, -0.0279,  ..., -1.0644, -1.9882, -2.0222],\n",
       "            [ 0.0332, -1.7696, -0.0760,  ..., -0.8386,  0.0382, -0.3731],\n",
       "            [ 1.5431, -0.3382,  2.3350,  ...,  1.7097,  0.7026, -0.5838],\n",
       "            ...,\n",
       "            [ 0.1058,  0.3848, -0.1312,  ...,  0.7278,  0.7726, -0.8798],\n",
       "            [ 0.2289,  1.2111,  0.3276,  ..., -0.1416,  0.0493, -0.3878],\n",
       "            [ 0.1065,  0.3839, -0.1312,  ...,  0.7286,  0.7737, -0.8796]]],\n",
       "          device='cuda:0', grad_fn=<SliceBackward>)],\n",
       "  [tensor([[[ 1.3394,  0.0085, -2.3403,  ..., -1.6764, -0.7550,  1.4601],\n",
       "            [ 0.0717, -1.8042, -0.1034,  ..., -0.7903,  0.0620, -0.4240],\n",
       "            [ 0.1376, -0.2631,  0.8937,  ...,  1.0681,  1.6646, -0.3793],\n",
       "            ...,\n",
       "            [ 0.0441, -0.8707, -0.2556,  ..., -1.8257,  0.0604,  0.0659],\n",
       "            [-1.0251, -1.2553, -0.1618,  ...,  0.3193, -0.8039, -0.4302],\n",
       "            [ 0.1309,  0.3416, -0.1560,  ...,  0.7763,  0.7859, -0.9291]],\n",
       "   \n",
       "           [[ 0.0480, -0.9066, -0.2707,  ..., -1.8152,  0.0511,  0.0643],\n",
       "            [ 0.0762, -1.8434, -0.1031,  ..., -0.7839,  0.0424, -0.4289],\n",
       "            [-0.0928, -0.5924,  0.5868,  ...,  0.5230, -0.5770, -0.3946],\n",
       "            ...,\n",
       "            [ 0.0476, -0.9058, -0.2699,  ..., -1.8186,  0.0542,  0.0646],\n",
       "            [ 0.4381, -2.0509, -2.1245,  ..., -0.9334, -0.5901, -0.0810],\n",
       "            [ 0.1525,  0.2925, -0.1801,  ...,  0.7772,  0.7675, -0.9354]],\n",
       "   \n",
       "           [[ 0.4387, -0.9227, -0.3280,  ...,  1.4953, -0.4532, -0.3426],\n",
       "            [ 0.0431, -1.8318, -0.1203,  ..., -0.8069,  0.0244, -0.4532],\n",
       "            [ 0.0261, -0.8947, -0.2701,  ..., -1.8429,  0.0357,  0.0322],\n",
       "            ...,\n",
       "            [ 0.1267,  0.3105, -0.1661,  ...,  0.7486,  0.7539, -0.9609],\n",
       "            [-1.0525, -1.2835, -0.1608,  ...,  0.2912, -0.8315, -0.4540],\n",
       "            [ 0.0262, -0.8940, -0.2700,  ..., -1.8415,  0.0337,  0.0327]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[ 1.3542, -0.0265, -2.3524,  ..., -1.6769, -0.7775,  1.4682],\n",
       "            [ 0.0754, -1.8394, -0.1158,  ..., -0.7906,  0.0319, -0.4042],\n",
       "            [ 0.1518, -0.3014,  0.8851,  ...,  1.0678,  1.6437, -0.3611],\n",
       "            ...,\n",
       "            [ 0.1472,  0.3016, -0.1778,  ...,  0.7679,  0.7643, -0.9142],\n",
       "            [-1.8668,  1.6955,  1.8174,  ...,  1.2129,  0.6638, -1.5788],\n",
       "            [-0.9747, -0.9389,  0.0660,  ..., -0.7179, -0.9565, -0.1753]],\n",
       "   \n",
       "           [[ 0.0544, -0.8538, -0.2660,  ..., -1.8658,  0.1091,  0.0493],\n",
       "            [ 0.0515, -0.8535, -0.2666,  ..., -1.8648,  0.1083,  0.0518],\n",
       "            [ 1.4296, -0.7718, -0.5383,  ..., -1.5112, -0.6193,  0.2453],\n",
       "            ...,\n",
       "            [ 0.1553,  0.3473, -0.1562,  ...,  0.7278,  0.8237, -0.9463],\n",
       "            [-1.0250, -1.2593, -0.1540,  ...,  0.2617, -0.7727, -0.4403],\n",
       "            [ 0.0536, -0.8538, -0.2657,  ..., -1.8658,  0.1091,  0.0502]],\n",
       "   \n",
       "           [[ 1.0861, -0.7966, -0.0279,  ..., -1.0644, -1.9882, -2.0222],\n",
       "            [ 0.0332, -1.7696, -0.0760,  ..., -0.8386,  0.0382, -0.3731],\n",
       "            [ 1.5431, -0.3382,  2.3350,  ...,  1.7097,  0.7026, -0.5838],\n",
       "            ...,\n",
       "            [ 0.1058,  0.3848, -0.1312,  ...,  0.7278,  0.7726, -0.8798],\n",
       "            [ 0.2289,  1.2111,  0.3276,  ..., -0.1416,  0.0493, -0.3878],\n",
       "            [ 0.1065,  0.3839, -0.1312,  ...,  0.7286,  0.7737, -0.8796]]],\n",
       "          device='cuda:0', grad_fn=<SliceBackward>)]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_acc(input:Tensor, t1:Tensor, t2:Tensor)->Rank0Tensor:\n",
    "    n = t1.shape[0]\n",
    "    input = input[0].argmax(dim=-1).view(n,-1)\n",
    "    t1 = t1.view(n,-1)\n",
    "    mask = t1 != vocab.pad_idx\n",
    "    return (input[mask]==t1[mask]).float().mean()\n",
    "\n",
    "def ns_acc(input:Tensor, t1:Tensor, t2:Tensor)->Rank0Tensor:\n",
    "    return accuracy(input[1], t2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics = [mask_acc, ns_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.2520301, tensor(0.5954), tensor(0.6895)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find()\n",
    "# learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mask_acc</th>\n",
       "      <th>ns_acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.417764</td>\n",
       "      <td>2.317451</td>\n",
       "      <td>0.598299</td>\n",
       "      <td>0.429834</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.165608</td>\n",
       "      <td>2.128812</td>\n",
       "      <td>0.608285</td>\n",
       "      <td>0.476660</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.096427</td>\n",
       "      <td>2.040318</td>\n",
       "      <td>0.634444</td>\n",
       "      <td>0.537158</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(3, 1e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
