{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastai.text import *\n",
    "from enum import Enum\n",
    "import torch\n",
    "from fastai.text.models.awd_lstm import *\n",
    "from fastai.text.models.transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(edgeitems=10, threshold=40, linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../')\n",
    "from src.fastai_data import *\n",
    "from src.encode_data import *\n",
    "from src.serve import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lmnp_transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../../data/midi/v15/piano_duet/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Stream Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ctx_len': 150,\n",
       " 'n_layers': 16,\n",
       " 'n_heads': 8,\n",
       " 'd_model': 256,\n",
       " 'd_head': 32,\n",
       " 'd_inner': 2048,\n",
       " 'resid_p': 0.1,\n",
       " 'attn_p': 0.1,\n",
       " 'ff_p': 0.1,\n",
       " 'embed_p': 0.1,\n",
       " 'output_p': 0.1,\n",
       " 'bias': False,\n",
       " 'scale': True,\n",
       " 'act': <Activation.GeLU: 3>,\n",
       " 'double_drop': True,\n",
       " 'tie_weights': True,\n",
       " 'out_bias': True,\n",
       " 'init': <function fastai.text.models.transformer.init_transformer(m)>,\n",
       " 'mem_len': 512,\n",
       " 'mask': True,\n",
       " 'pad_idx': 1,\n",
       " 'bos_idx': 0,\n",
       " 'sep_idx': 8,\n",
       " 'transpose_range': (0, 12),\n",
       " 'note_range': (9, 138),\n",
       " 'bs': 16,\n",
       " 'bptt': 256,\n",
       " 'vocab_size': 274}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = v15s_config(vocab); config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fastai Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_tfms = [mask_tfm, next_sentence_tfm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLTFMS: [<function mask_tfm at 0x7f9916b08d90>, <function next_sentence_tfm at 0x7f9916b08d08>]\n"
     ]
    }
   ],
   "source": [
    "data = load_music_data(path, cache_name='tmp/sample', vocab=vocab, y_offset=0, dl_tfms=dl_tfms, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb,yb = data.one_batch(cpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[155,  68, 155,  ...,   8,   4,  52],\n",
       "        [155,   4, 155,  ...,   4, 147,  52],\n",
       "        [  4,  68, 155,  ...,   4, 147,  55],\n",
       "        ...,\n",
       "        [155,  72, 155,  ...,   4, 147,  57],\n",
       "        [155,  68, 155,  ...,   8, 147,  53],\n",
       "        [155,  68,  34,  ...,   4, 147,  52]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[  1,   1,   1,  ...,   1, 147,   1],\n",
       "         [  1,  71,   1,  ...,   8,   1,  52],\n",
       "         [155,   1,   1,  ...,   8,   1,   1],\n",
       "         ...,\n",
       "         [  1,   1,   1,  ...,   8,   1,   1],\n",
       "         [  1,   1,   1,  ...,   1,   1,  53],\n",
       "         [  1,  68, 155,  ...,   8,   1,   1]], device='cuda:0'),\n",
       " tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LMNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_len = 0\n",
    "# x_len = 16 # bptt\n",
    "# seq_len = m_len+x_len\n",
    "# torch.triu(torch.ones(x_len, seq_len), diagonal=m_len).byte()[None,None].cpu().numpy()\n",
    "# torch.triu(torch.ones(x_len, seq_len), diagonal=m_len+1).byte()[None,None].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEmbedding(nn.Module):\n",
    "    \"Embedding + positional encoding + dropout\"\n",
    "    def __init__(self, vocab_sz:int, emb_sz:int, inp_p:float=0.):\n",
    "        super().__init__()\n",
    "        self.emb_sz = emb_sz\n",
    "        self.embed = embedding(vocab_sz, emb_sz)\n",
    "        self.pos_enc = PositionalEncoding(emb_sz)\n",
    "        self.drop = nn.Dropout(inp_p)\n",
    "    \n",
    "    def forward(self, inp): \n",
    "        pos = torch.arange(0, inp.size(1), device=inp.device).float()\n",
    "        return self.drop(self.embed(inp) * math.sqrt(self.emb_sz) + self.pos_enc(pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicTransformer(nn.Module):\n",
    "    \"Transformer model: https://arxiv.org/abs/1706.03762.\"\n",
    "    def __init__(self, embed:nn.Module, n_layers:int, n_heads:int, d_model:int, d_head:int, d_inner:int, \n",
    "                 resid_p:float=0., attn_p:float=0., ff_p:float=0., bias:bool=True, scale:bool=True,\n",
    "                 act:Activation=Activation.ReLU, double_drop:bool=True, attn_cls:Callable=MultiHeadAttention,\n",
    "                 mask:bool=True, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mask = mask\n",
    "        self.encoder = embed\n",
    "        self.layers = nn.ModuleList([DecoderLayer(n_heads, d_model, d_head, d_inner, resid_p=resid_p, attn_p=attn_p,\n",
    "                      ff_p=ff_p, bias=bias, scale=scale, act=act, double_drop=double_drop, \n",
    "                      attn_cls=attn_cls) for k in range(n_layers)])\n",
    "    \n",
    "    def reset(self): pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs, x_len, _ = x.size()\n",
    "        mask = window_mask(x_len, x.device) if self.mask else None\n",
    "#         mask = torch.triu(torch.(x_len, x_len), diagonal=1).byte()[None,None] if self.mask else None\n",
    "        #[None,:,:None] for einsum implementation of attention\n",
    "        for layer in self.layers: x = layer(x, mask=mask)\n",
    "        return ([x],[x]) #For the LinearDecoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.model[0].layers[0].mhra.residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.learner import _model_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['mem_len'] = 0\n",
    "config['mask'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ctx_len': 150,\n",
       " 'n_layers': 16,\n",
       " 'n_heads': 8,\n",
       " 'd_model': 256,\n",
       " 'd_head': 32,\n",
       " 'd_inner': 2048,\n",
       " 'resid_p': 0.0,\n",
       " 'attn_p': 0.0,\n",
       " 'ff_p': 0.0,\n",
       " 'embed_p': 0.0,\n",
       " 'output_p': 0.0,\n",
       " 'bias': False,\n",
       " 'scale': True,\n",
       " 'act': <Activation.GeLU: 3>,\n",
       " 'double_drop': True,\n",
       " 'tie_weights': True,\n",
       " 'out_bias': True,\n",
       " 'mem_len': 0,\n",
       " 'mask': False,\n",
       " 'pad_idx': 1,\n",
       " 'bos_idx': 0,\n",
       " 'sep_idx': 8,\n",
       " 'transpose_range': (0, 12),\n",
       " 'note_range': (9, 138),\n",
       " 'bs': 16,\n",
       " 'bptt': 256,\n",
       " 'vocab_size': 274}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "_model_meta[MusicTransformer] = _model_meta[Transformer]\n",
    "_model_meta[MusicTransformer]['config_lm'] = config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertHead(nn.Module):\n",
    "    def __init__(self, embed, encoder, mask_decoder, ns_decoder, s2s_decoder):\n",
    "        super().__init__()\n",
    "        self.embed = embed\n",
    "        self.encoder = encoder\n",
    "        self.mask_decoder = mask_decoder\n",
    "        self.ns_decoder = ns_decoder\n",
    "        self.s2s_decoder = s2s_decoder\n",
    "        \n",
    "    def forward(self, x, y=None):\n",
    "        x_emb = self.embed(x)\n",
    "        x_enc = self.encoder(x_emb)\n",
    "        \n",
    "        if y is None: # mask, and next sentence task\n",
    "            return self.mask_decoder(x_enc), self.ns_decoder(x_enc)\n",
    "        \n",
    "        y_emb = self.embed(y)\n",
    "        return self.mask_decoder(x_enc), self.s2s_decoder(x_enc, y_emb)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return [self.encoder, self.mask_decoder, self.ns_decoder, self.s2s_decoder][idx]\n",
    "        \n",
    "    \"A sequential module that passes the reset call to its children.\"\n",
    "    def reset(self): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S2SDecoderBlock(nn.Module):\n",
    "    \"Decoder block of a Transformer model.\"\n",
    "    #Can't use Sequential directly cause more than one input...\n",
    "    def __init__(self, n_heads:int, d_model:int, d_head:int, d_inner:int, resid_p:float=0., attn_p:float=0., ff_p:float=0.,\n",
    "                 bias:bool=True, scale:bool=True, double_drop:bool=True, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha1 = MultiHeadAttention(n_heads, d_model, d_head, resid_p=resid_p, attn_p=attn_p, bias=bias, scale=scale)\n",
    "        self.mha2 = MultiHeadAttention(n_heads, d_model, d_head, resid_p=resid_p, attn_p=attn_p, bias=bias, scale=scale)\n",
    "        self.ff   = feed_forward(d_model, d_inner, ff_p=ff_p, double_drop=double_drop)\n",
    "    \n",
    "    def forward(self, x:Tensor, enc:Tensor, mask_in:Tensor=None, mask_out:Tensor=None): \n",
    "        y = self.mha1(x, x, x, mask_out)\n",
    "        return self.ff(self.mha2(y, enc, enc, mask=mask_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_mask(x_len, device, m_len=0, size=(1,1)):\n",
    "    mem_mask = np.zeros((x_len,m_len))\n",
    "    tri_mask = np.triu(np.ones((x_len//win_size+1,x_len//win_size+1)),k=k)\n",
    "    window_mask = tri_mask.repeat(win_size,axis=0).repeat(win_size,axis=1)[:x_len,:x_len]\n",
    "    np_mask = np.concatenate((mem_mask, window_mask), axis=1)\n",
    "    mask = torch.tensor(np_mask, device=device).byte()[None,None]\n",
    "    return mask\n",
    "    \n",
    "def rand_window_mask(x_len,m_len,device,max_size=3,p=0.2,is_eval=False):\n",
    "    if is_eval or m_len == 0 or np.random.rand() >= p: \n",
    "        win_size,k = (1,1)\n",
    "    else: win_size,k = (np.random.randint(0,max_size)+1,0)\n",
    "    return window_mask(x_len, device, m_len, size=(win_size,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_mask(inp, pad_idx:int=1):\n",
    "    return torch.triu(inp.new_ones(inp.size(1),inp.size(1)), diagonal=1)[None,None].byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S2SDecoder(nn.Module):\n",
    "    def __init__(self, embed, n_hid, vocab_sz, n_layers, **kwargs):\n",
    "        super().__init__()\n",
    "        self.decoder = nn.ModuleList([S2SDecoderBlock(**kwargs) for _ in range(n_layers)])\n",
    "        self.head = MusicLinearDecoder(n_hid, vocab_sz, tie_encoder=embed.embed, **kwargs)\n",
    "        \n",
    "#         self.pad_idx = pad_idx\n",
    "        \n",
    "    def forward(self, inp, out):\n",
    "        x_len = inp.shape[-1]\n",
    "#         mask_out = rand_window_mask(x_len, 0, inp.device, is_eval=not self.training)\n",
    "        mask_out = window_mask(x_len, inp.device)\n",
    "    \n",
    "        out = self.embed(out)\n",
    "        for dec_block in self.decoder: out = dec_block(out, inp, mask_in, mask_out)\n",
    "        return self.head(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MusicLinearDecoder(nn.Module):\n",
    "    \"To go on top of a RNNCore module and create a Language Model.\"\n",
    "    initrange=0.1\n",
    "\n",
    "    def __init__(self, n_hid:int, n_out:int, output_p:float, tie_encoder:nn.Module=None, bias:bool=True, **kwargs):\n",
    "        super().__init__()\n",
    "        self.decoder = nn.Linear(n_hid, n_out, bias=bias)\n",
    "        self.decoder.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.output_dp = RNNDropout(output_p)\n",
    "        if bias: self.decoder.bias.data.zero_()\n",
    "        if tie_encoder: self.decoder.weight = tie_encoder.weight\n",
    "\n",
    "    def forward(self, input:Tuple[Tensor,Tensor])->Tuple[Tensor,Tensor,Tensor]:\n",
    "        raw_outputs, outputs = input\n",
    "        output = self.output_dp(outputs[-1])\n",
    "        decoded = self.decoder(output)\n",
    "        return decoded, raw_outputs, outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_music_model(vocab_sz:int, config:dict=None, drop_mult:float=1.):\n",
    "    \"Create a language model from `arch` and its `config`, maybe `pretrained`.\"\n",
    "    for k in config.keys(): \n",
    "        if k.endswith('_p'): config[k] *= drop_mult\n",
    "#     tie_weights,output_p,out_bias = map(config.pop, ['tie_weights', 'output_p', 'out_bias'])\n",
    "    tie_weights,output_p,out_bias = map(config.get, ['tie_weights', 'output_p', 'out_bias'])\n",
    "    init = config.pop('init') if 'init' in config else None\n",
    "    n_hid = config['d_model']\n",
    "    embed = TransformerEmbedding(vocab_sz, n_hid, inp_p=config['embed_p'])\n",
    "    encoder = MusicTransformer(embed=embed.embed, **config)\n",
    "    mask_decoder = MusicLinearDecoder(n_hid, vocab_sz, output_p, tie_encoder=embed.embed, bias=out_bias)\n",
    "    ns_decoder = MusicLinearDecoder(n_hid, 4, output_p, tie_encoder=None, bias=out_bias)\n",
    "    s2s_decoder = S2SDecoder(embed, n_hid, vocab_sz, **config)\n",
    "    model = BertHead(embed, encoder, mask_decoder, ns_decoder, s2s_decoder)\n",
    "    return model if init is None else model.apply(init)\n",
    "\n",
    "\n",
    "def music_model_learner(data:DataBunch, config:dict=None, drop_mult:float=1., pretrained:bool=False,\n",
    "                        pretrained_fnames:OptStrTuple=None, **learn_kwargs) -> 'LanguageLearner':\n",
    "    \"Create a `Learner` with a language model from `data` and `arch`.\"\n",
    "    model = get_music_model(config['vocab_size'], config=config, drop_mult=drop_mult)\n",
    "    \n",
    "    meta = _model_meta[Transformer]\n",
    "    learn = MusicLearner(data, model, split_func=meta['split_lm'], \n",
    "                         bos_idx=config['bos_idx'], sep_idx=config['sep_idx'],\n",
    "                        **learn_kwargs)\n",
    "    \n",
    "    if pretrained:\n",
    "        if 'url' not in meta: \n",
    "            warn(\"There are no pretrained weights for that architecture yet!\")\n",
    "            return learn\n",
    "        model_path = untar_data(meta['url'], data=False)\n",
    "        fnames = [list(model_path.glob(f'*.{ext}'))[0] for ext in ['pth', 'pkl']]\n",
    "        learn.load_pretrained(*fnames)\n",
    "        learn.freeze()\n",
    "    if pretrained_fnames is not None:\n",
    "        fnames = [learn.path/learn.model_dir/f'{fn}.{ext}' for fn,ext in zip(pretrained_fnames, ['pth', 'pkl'])]\n",
    "        learn.load_pretrained(*fnames)\n",
    "        learn.freeze()\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sep_idx: 8\n"
     ]
    }
   ],
   "source": [
    "learn = music_model_learner(data, config, drop_mult=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb,yb = data.one_batch(cpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLoss():\n",
    "    def __init__(self, mask_loss, sent_loss):\n",
    "        self.mask_loss = mask_loss\n",
    "        self.sent_loss = sent_loss\n",
    "        \n",
    "    def __call__(self, input:Tensor, target:Tensor, target_sen:Tensor, **kwargs)->Rank0Tensor:\n",
    "        m = self.mask_loss.__call__(input[0], target, **kwargs)\n",
    "        s = self.sent_loss.__call__(input[1], target_sen, **kwargs)\n",
    "        return m + s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertTrainer(LearnerCallback):\n",
    "    \"`Callback` that regroups lr adjustment to seq_len, AR and TAR.\"\n",
    "    def __init__(self, learn:Learner):\n",
    "        super().__init__(learn)\n",
    "        \n",
    "    def on_loss_begin(self, last_output:Tuple[Tensor,Tensor,Tensor], **kwargs):\n",
    "        \"Save the extra outputs for later and only returns the true output.\"\n",
    "        return {'last_output': (last_output[0][0], last_output[1][0]) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(learn.callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.callbacks = [BertTrainer(learn, alpha=2, beta=1)]\n",
    "learn.callbacks = [BertTrainer(learn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func = BertLoss(CrossEntropyFlat(ignore_index=vocab.pad_idx), CrossEntropyFlat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[[-0.0333, -0.2630, -0.0281,  ..., -0.1831, -0.0589,  0.1242],\n",
       "           [-0.1453, -0.2368, -0.0192,  ..., -0.1638, -0.1066,  0.1291],\n",
       "           [-0.1413, -0.3135, -0.0474,  ..., -0.0977, -0.0727,  0.1028],\n",
       "           ...,\n",
       "           [-0.1811, -0.1423,  0.0825,  ..., -0.1925, -0.0855,  0.0012],\n",
       "           [-0.2093, -0.1797,  0.0943,  ..., -0.1873, -0.0806,  0.0069],\n",
       "           [-0.2064, -0.1918,  0.0996,  ..., -0.1923, -0.0564,  0.0511]],\n",
       "  \n",
       "          [[-0.0359, -0.2567, -0.0225,  ..., -0.2064, -0.0432,  0.1188],\n",
       "           [-0.1053, -0.2352, -0.0572,  ..., -0.1237, -0.1362,  0.1502],\n",
       "           [-0.1404, -0.3143, -0.0448,  ..., -0.0981, -0.0744,  0.1048],\n",
       "           ...,\n",
       "           [-0.2232, -0.1973,  0.0741,  ..., -0.2047, -0.0783,  0.0179],\n",
       "           [-0.2075, -0.1832,  0.0969,  ..., -0.1880, -0.0828,  0.0105],\n",
       "           [-0.2437, -0.2103,  0.1251,  ..., -0.1699, -0.0869,  0.0407]],\n",
       "  \n",
       "          [[-0.0312, -0.2696, -0.0255,  ..., -0.1817, -0.0611,  0.1243],\n",
       "           [-0.1325, -0.2777, -0.0169,  ..., -0.1391, -0.1105,  0.1245],\n",
       "           [-0.1389, -0.3197, -0.0450,  ..., -0.0966, -0.0741,  0.1029],\n",
       "           ...,\n",
       "           [-0.1886, -0.1722,  0.0933,  ..., -0.2313, -0.0544, -0.0265],\n",
       "           [-0.2063, -0.1864,  0.0956,  ..., -0.1863, -0.0839,  0.0066],\n",
       "           [-0.2303, -0.1842,  0.0965,  ..., -0.1986, -0.0550,  0.0363]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-0.0305, -0.2611, -0.0289,  ..., -0.1819, -0.0613,  0.1221],\n",
       "           [-0.0774, -0.2788, -0.0291,  ..., -0.0852, -0.0776,  0.1477],\n",
       "           [-0.1383, -0.3114, -0.0487,  ..., -0.0965, -0.0754,  0.1014],\n",
       "           ...,\n",
       "           [-0.1875, -0.1650,  0.0909,  ..., -0.2307, -0.0543, -0.0269],\n",
       "           [-0.2049, -0.1796,  0.0934,  ..., -0.1861, -0.0840,  0.0065],\n",
       "           [-0.1760, -0.1765,  0.1076,  ..., -0.1829, -0.0455,  0.0530]],\n",
       "  \n",
       "          [[-0.0326, -0.2647, -0.0245,  ..., -0.1823, -0.0622,  0.1269],\n",
       "           [-0.1446, -0.2943, -0.0269,  ..., -0.1072, -0.1336,  0.1334],\n",
       "           [-0.1397, -0.3143, -0.0437,  ..., -0.0971, -0.0753,  0.1050],\n",
       "           ...,\n",
       "           [-0.1797, -0.1447,  0.0859,  ..., -0.1917, -0.0899,  0.0033],\n",
       "           [-0.2075, -0.1823,  0.0977,  ..., -0.1863, -0.0850,  0.0086],\n",
       "           [-0.2023, -0.1590,  0.1122,  ..., -0.2093, -0.0400,  0.0236]],\n",
       "  \n",
       "          [[-0.0282, -0.2758, -0.0243,  ..., -0.1819, -0.0578,  0.1276],\n",
       "           [-0.1296, -0.2838, -0.0155,  ..., -0.1390, -0.1072,  0.1276],\n",
       "           [-0.1360, -0.3262, -0.0434,  ..., -0.0966, -0.0707,  0.1053],\n",
       "           ...,\n",
       "           [-0.1769, -0.1553,  0.0856,  ..., -0.1927, -0.0855,  0.0056],\n",
       "           [-0.1886, -0.1792,  0.1099,  ..., -0.1642, -0.0695,  0.0169],\n",
       "           [-0.2000, -0.1693,  0.1121,  ..., -0.2099, -0.0353,  0.0258]]],\n",
       "         device='cuda:0', grad_fn=<AddBackward0>),\n",
       "  [tensor([[[-0.4862, -1.6539,  1.0410,  ..., -0.9382,  1.2419,  0.4652],\n",
       "            [ 0.5933, -0.9823,  1.7238,  ..., -1.1960,  0.8535,  0.0291],\n",
       "            [ 0.3604, -1.0433,  1.6340,  ..., -0.9836,  0.9906,  0.3449],\n",
       "            ...,\n",
       "            [ 0.4838, -1.4156,  0.6020,  ..., -0.7200,  0.5958,  0.2351],\n",
       "            [-0.0560, -2.0356,  1.0048,  ..., -0.6956,  0.7350,  0.2916],\n",
       "            [-0.5562, -2.1299,  1.3013,  ..., -0.8801,  0.6442,  0.4226]],\n",
       "   \n",
       "           [[-0.4100, -1.4049,  0.9396,  ..., -1.2559,  1.4211,  0.1615],\n",
       "            [ 0.6005, -1.2619,  1.7659,  ..., -1.2673,  1.1661,  0.0332],\n",
       "            [ 0.3662, -1.0320,  1.6604,  ..., -0.9644,  0.9784,  0.3336],\n",
       "            ...,\n",
       "            [ 0.3330, -1.6540,  0.3930,  ..., -0.6710,  0.6799,  0.2292],\n",
       "            [-0.0495, -2.0193,  1.0259,  ..., -0.6700,  0.7189,  0.2864],\n",
       "            [-0.6177, -1.9319,  1.4303,  ..., -1.0225,  0.7966,  0.4030]],\n",
       "   \n",
       "           [[-0.4307, -1.6575,  1.0930,  ..., -0.9453,  1.2401,  0.4688],\n",
       "            [ 0.6306, -1.1842,  1.6672,  ..., -1.1414,  1.1467,  0.0170],\n",
       "            [ 0.4150, -1.0506,  1.6902,  ..., -0.9869,  0.9850,  0.3517],\n",
       "            ...,\n",
       "            [ 0.4409, -1.2274,  0.3408,  ..., -0.9345,  0.9570,  0.4803],\n",
       "            [ 0.0034, -2.0462,  1.0492,  ..., -0.6966,  0.7304,  0.3059],\n",
       "            [-0.5293, -2.0542,  1.6363,  ..., -0.8371,  0.6545,  0.3443]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[-0.5005, -1.6495,  1.0666,  ..., -0.9350,  1.2203,  0.4519],\n",
       "            [ 0.4279, -1.3281,  1.8969,  ..., -1.1671,  1.1410, -0.0099],\n",
       "            [ 0.3442, -1.0419,  1.6592,  ..., -0.9795,  0.9676,  0.3331],\n",
       "            ...,\n",
       "            [ 0.3596, -1.2159,  0.3160,  ..., -0.9190,  0.9447,  0.4466],\n",
       "            [-0.0771, -2.0266,  1.0212,  ..., -0.6810,  0.7199,  0.2737],\n",
       "            [-0.6847, -2.0753,  1.3762,  ..., -1.1081,  0.9753,  0.5851]],\n",
       "   \n",
       "           [[-0.4664, -1.6290,  1.0827,  ..., -0.9357,  1.2570,  0.4713],\n",
       "            [ 0.4465, -0.9696,  1.4882,  ..., -1.4151,  1.0860,  0.0271],\n",
       "            [ 0.3831, -1.0169,  1.6786,  ..., -0.9781,  1.0010,  0.3521],\n",
       "            ...,\n",
       "            [ 0.5035, -1.3910,  0.6414,  ..., -0.7106,  0.5937,  0.2487],\n",
       "            [-0.0368, -2.0145,  1.0436,  ..., -0.6853,  0.7386,  0.3056],\n",
       "            [-0.6201, -1.8781,  1.4162,  ..., -1.0523,  0.8955,  0.4904]],\n",
       "   \n",
       "           [[-0.3988, -1.6895,  1.1046,  ..., -0.9297,  1.2599,  0.4596],\n",
       "            [ 0.6560, -1.2086,  1.6815,  ..., -1.1264,  1.1652,  0.0072],\n",
       "            [ 0.4446, -1.0721,  1.7044,  ..., -0.9738,  1.0032,  0.3453],\n",
       "            ...,\n",
       "            [ 0.5688, -1.4449,  0.6656,  ..., -0.7059,  0.6103,  0.2435],\n",
       "            [ 0.0542, -1.9372,  1.1685,  ..., -1.0904,  0.7298,  0.4094],\n",
       "            [-0.5551, -1.9315,  1.4403,  ..., -1.0490,  0.9064,  0.4777]]],\n",
       "          device='cuda:0', grad_fn=<AddcmulBackward>)],\n",
       "  [tensor([[[-0.4862, -1.6539,  1.0410,  ..., -0.9382,  1.2419,  0.4652],\n",
       "            [ 0.5933, -0.9823,  1.7238,  ..., -1.1960,  0.8535,  0.0291],\n",
       "            [ 0.3604, -1.0433,  1.6340,  ..., -0.9836,  0.9906,  0.3449],\n",
       "            ...,\n",
       "            [ 0.4838, -1.4156,  0.6020,  ..., -0.7200,  0.5958,  0.2351],\n",
       "            [-0.0560, -2.0356,  1.0048,  ..., -0.6956,  0.7350,  0.2916],\n",
       "            [-0.5562, -2.1299,  1.3013,  ..., -0.8801,  0.6442,  0.4226]],\n",
       "   \n",
       "           [[-0.4100, -1.4049,  0.9396,  ..., -1.2559,  1.4211,  0.1615],\n",
       "            [ 0.6005, -1.2619,  1.7659,  ..., -1.2673,  1.1661,  0.0332],\n",
       "            [ 0.3662, -1.0320,  1.6604,  ..., -0.9644,  0.9784,  0.3336],\n",
       "            ...,\n",
       "            [ 0.3330, -1.6540,  0.3930,  ..., -0.6710,  0.6799,  0.2292],\n",
       "            [-0.0495, -2.0193,  1.0259,  ..., -0.6700,  0.7189,  0.2864],\n",
       "            [-0.6177, -1.9319,  1.4303,  ..., -1.0225,  0.7966,  0.4030]],\n",
       "   \n",
       "           [[-0.4307, -1.6575,  1.0930,  ..., -0.9453,  1.2401,  0.4688],\n",
       "            [ 0.6306, -1.1842,  1.6672,  ..., -1.1414,  1.1467,  0.0170],\n",
       "            [ 0.4150, -1.0506,  1.6902,  ..., -0.9869,  0.9850,  0.3517],\n",
       "            ...,\n",
       "            [ 0.4409, -1.2274,  0.3408,  ..., -0.9345,  0.9570,  0.4803],\n",
       "            [ 0.0034, -2.0462,  1.0492,  ..., -0.6966,  0.7304,  0.3059],\n",
       "            [-0.5293, -2.0542,  1.6363,  ..., -0.8371,  0.6545,  0.3443]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[-0.5005, -1.6495,  1.0666,  ..., -0.9350,  1.2203,  0.4519],\n",
       "            [ 0.4279, -1.3281,  1.8969,  ..., -1.1671,  1.1410, -0.0099],\n",
       "            [ 0.3442, -1.0419,  1.6592,  ..., -0.9795,  0.9676,  0.3331],\n",
       "            ...,\n",
       "            [ 0.3596, -1.2159,  0.3160,  ..., -0.9190,  0.9447,  0.4466],\n",
       "            [-0.0771, -2.0266,  1.0212,  ..., -0.6810,  0.7199,  0.2737],\n",
       "            [-0.6847, -2.0753,  1.3762,  ..., -1.1081,  0.9753,  0.5851]],\n",
       "   \n",
       "           [[-0.4664, -1.6290,  1.0827,  ..., -0.9357,  1.2570,  0.4713],\n",
       "            [ 0.4465, -0.9696,  1.4882,  ..., -1.4151,  1.0860,  0.0271],\n",
       "            [ 0.3831, -1.0169,  1.6786,  ..., -0.9781,  1.0010,  0.3521],\n",
       "            ...,\n",
       "            [ 0.5035, -1.3910,  0.6414,  ..., -0.7106,  0.5937,  0.2487],\n",
       "            [-0.0368, -2.0145,  1.0436,  ..., -0.6853,  0.7386,  0.3056],\n",
       "            [-0.6201, -1.8781,  1.4162,  ..., -1.0523,  0.8955,  0.4904]],\n",
       "   \n",
       "           [[-0.3988, -1.6895,  1.1046,  ..., -0.9297,  1.2599,  0.4596],\n",
       "            [ 0.6560, -1.2086,  1.6815,  ..., -1.1264,  1.1652,  0.0072],\n",
       "            [ 0.4446, -1.0721,  1.7044,  ..., -0.9738,  1.0032,  0.3453],\n",
       "            ...,\n",
       "            [ 0.5688, -1.4449,  0.6656,  ..., -0.7059,  0.6103,  0.2435],\n",
       "            [ 0.0542, -1.9372,  1.1685,  ..., -1.0904,  0.7298,  0.4094],\n",
       "            [-0.5551, -1.9315,  1.4403,  ..., -1.0490,  0.9064,  0.4777]]],\n",
       "          device='cuda:0', grad_fn=<AddcmulBackward>)]),\n",
       " (tensor([[[-0.2451, -1.7801, -0.9236,  1.4304],\n",
       "           [-0.8463, -1.3830, -0.8901,  0.9430],\n",
       "           [-0.9663, -1.2053, -0.9945,  1.1606],\n",
       "           ...,\n",
       "           [-1.2316, -1.4514, -0.7755,  1.0592],\n",
       "           [-1.4585, -1.4283, -0.6952,  1.1285],\n",
       "           [-1.8193, -1.5056, -0.8332,  1.4624]],\n",
       "  \n",
       "          [[-0.2223, -1.7723, -1.0257,  0.9213],\n",
       "           [-0.7228, -1.3676, -0.7509,  0.9609],\n",
       "           [-0.9874, -1.1970, -0.9828,  1.1535],\n",
       "           ...,\n",
       "           [-1.2242, -1.4583, -0.9528,  1.0468],\n",
       "           [-1.4881, -1.4132, -0.6879,  1.1169],\n",
       "           [-1.7073, -1.2183, -0.7168,  1.4966]],\n",
       "  \n",
       "          [[-0.2489, -1.7862, -0.9266,  1.4196],\n",
       "           [-0.8785, -1.3579, -1.1840,  1.0433],\n",
       "           [-0.9716, -1.2146, -0.9991,  1.1490],\n",
       "           ...,\n",
       "           [-1.1746, -1.5680, -0.9676,  0.7847],\n",
       "           [-1.4736, -1.4386, -0.7065,  1.1146],\n",
       "           [-1.6743, -1.4218, -0.7373,  1.1888]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-0.2474, -1.7673, -0.9168,  1.4394],\n",
       "           [-0.6940, -1.2277, -1.1568,  0.8514],\n",
       "           [-0.9692, -1.1911, -0.9864,  1.1688],\n",
       "           ...,\n",
       "           [-1.1583, -1.5426, -0.9526,  0.8118],\n",
       "           [-1.4549, -1.4170, -0.6904,  1.1394],\n",
       "           [-1.6052, -1.4828, -0.8172,  1.2895]],\n",
       "  \n",
       "          [[-0.2469, -1.7879, -0.9172,  1.4176],\n",
       "           [-0.6697, -1.3454, -0.8163,  1.3050],\n",
       "           [-0.9685, -1.2137, -0.9868,  1.1473],\n",
       "           ...,\n",
       "           [-1.2395, -1.4602, -0.7747,  1.0459],\n",
       "           [-1.4684, -1.4384, -0.6979,  1.1167],\n",
       "           [-1.6300, -1.4841, -0.8695,  1.0791]],\n",
       "  \n",
       "          [[-0.2916, -1.7789, -0.9267,  1.4074],\n",
       "           [-0.9202, -1.3462, -1.1852,  1.0299],\n",
       "           [-1.0130, -1.2045, -1.0002,  1.1391],\n",
       "           ...,\n",
       "           [-1.2857, -1.4492, -0.7853,  1.0316],\n",
       "           [-1.6652, -1.6564, -0.8457,  1.0329],\n",
       "           [-1.6758, -1.4705, -0.8781,  1.0639]]], device='cuda:0',\n",
       "         grad_fn=<AddBackward0>),\n",
       "  [tensor([[[-0.4862, -1.6539,  1.0410,  ..., -0.9382,  1.2419,  0.4652],\n",
       "            [ 0.5933, -0.9823,  1.7238,  ..., -1.1960,  0.8535,  0.0291],\n",
       "            [ 0.3604, -1.0433,  1.6340,  ..., -0.9836,  0.9906,  0.3449],\n",
       "            ...,\n",
       "            [ 0.4838, -1.4156,  0.6020,  ..., -0.7200,  0.5958,  0.2351],\n",
       "            [-0.0560, -2.0356,  1.0048,  ..., -0.6956,  0.7350,  0.2916],\n",
       "            [-0.5562, -2.1299,  1.3013,  ..., -0.8801,  0.6442,  0.4226]],\n",
       "   \n",
       "           [[-0.4100, -1.4049,  0.9396,  ..., -1.2559,  1.4211,  0.1615],\n",
       "            [ 0.6005, -1.2619,  1.7659,  ..., -1.2673,  1.1661,  0.0332],\n",
       "            [ 0.3662, -1.0320,  1.6604,  ..., -0.9644,  0.9784,  0.3336],\n",
       "            ...,\n",
       "            [ 0.3330, -1.6540,  0.3930,  ..., -0.6710,  0.6799,  0.2292],\n",
       "            [-0.0495, -2.0193,  1.0259,  ..., -0.6700,  0.7189,  0.2864],\n",
       "            [-0.6177, -1.9319,  1.4303,  ..., -1.0225,  0.7966,  0.4030]],\n",
       "   \n",
       "           [[-0.4307, -1.6575,  1.0930,  ..., -0.9453,  1.2401,  0.4688],\n",
       "            [ 0.6306, -1.1842,  1.6672,  ..., -1.1414,  1.1467,  0.0170],\n",
       "            [ 0.4150, -1.0506,  1.6902,  ..., -0.9869,  0.9850,  0.3517],\n",
       "            ...,\n",
       "            [ 0.4409, -1.2274,  0.3408,  ..., -0.9345,  0.9570,  0.4803],\n",
       "            [ 0.0034, -2.0462,  1.0492,  ..., -0.6966,  0.7304,  0.3059],\n",
       "            [-0.5293, -2.0542,  1.6363,  ..., -0.8371,  0.6545,  0.3443]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[-0.5005, -1.6495,  1.0666,  ..., -0.9350,  1.2203,  0.4519],\n",
       "            [ 0.4279, -1.3281,  1.8969,  ..., -1.1671,  1.1410, -0.0099],\n",
       "            [ 0.3442, -1.0419,  1.6592,  ..., -0.9795,  0.9676,  0.3331],\n",
       "            ...,\n",
       "            [ 0.3596, -1.2159,  0.3160,  ..., -0.9190,  0.9447,  0.4466],\n",
       "            [-0.0771, -2.0266,  1.0212,  ..., -0.6810,  0.7199,  0.2737],\n",
       "            [-0.6847, -2.0753,  1.3762,  ..., -1.1081,  0.9753,  0.5851]],\n",
       "   \n",
       "           [[-0.4664, -1.6290,  1.0827,  ..., -0.9357,  1.2570,  0.4713],\n",
       "            [ 0.4465, -0.9696,  1.4882,  ..., -1.4151,  1.0860,  0.0271],\n",
       "            [ 0.3831, -1.0169,  1.6786,  ..., -0.9781,  1.0010,  0.3521],\n",
       "            ...,\n",
       "            [ 0.5035, -1.3910,  0.6414,  ..., -0.7106,  0.5937,  0.2487],\n",
       "            [-0.0368, -2.0145,  1.0436,  ..., -0.6853,  0.7386,  0.3056],\n",
       "            [-0.6201, -1.8781,  1.4162,  ..., -1.0523,  0.8955,  0.4904]],\n",
       "   \n",
       "           [[-0.3988, -1.6895,  1.1046,  ..., -0.9297,  1.2599,  0.4596],\n",
       "            [ 0.6560, -1.2086,  1.6815,  ..., -1.1264,  1.1652,  0.0072],\n",
       "            [ 0.4446, -1.0721,  1.7044,  ..., -0.9738,  1.0032,  0.3453],\n",
       "            ...,\n",
       "            [ 0.5688, -1.4449,  0.6656,  ..., -0.7059,  0.6103,  0.2435],\n",
       "            [ 0.0542, -1.9372,  1.1685,  ..., -1.0904,  0.7298,  0.4094],\n",
       "            [-0.5551, -1.9315,  1.4403,  ..., -1.0490,  0.9064,  0.4777]]],\n",
       "          device='cuda:0', grad_fn=<AddcmulBackward>)],\n",
       "  [tensor([[[-0.4862, -1.6539,  1.0410,  ..., -0.9382,  1.2419,  0.4652],\n",
       "            [ 0.5933, -0.9823,  1.7238,  ..., -1.1960,  0.8535,  0.0291],\n",
       "            [ 0.3604, -1.0433,  1.6340,  ..., -0.9836,  0.9906,  0.3449],\n",
       "            ...,\n",
       "            [ 0.4838, -1.4156,  0.6020,  ..., -0.7200,  0.5958,  0.2351],\n",
       "            [-0.0560, -2.0356,  1.0048,  ..., -0.6956,  0.7350,  0.2916],\n",
       "            [-0.5562, -2.1299,  1.3013,  ..., -0.8801,  0.6442,  0.4226]],\n",
       "   \n",
       "           [[-0.4100, -1.4049,  0.9396,  ..., -1.2559,  1.4211,  0.1615],\n",
       "            [ 0.6005, -1.2619,  1.7659,  ..., -1.2673,  1.1661,  0.0332],\n",
       "            [ 0.3662, -1.0320,  1.6604,  ..., -0.9644,  0.9784,  0.3336],\n",
       "            ...,\n",
       "            [ 0.3330, -1.6540,  0.3930,  ..., -0.6710,  0.6799,  0.2292],\n",
       "            [-0.0495, -2.0193,  1.0259,  ..., -0.6700,  0.7189,  0.2864],\n",
       "            [-0.6177, -1.9319,  1.4303,  ..., -1.0225,  0.7966,  0.4030]],\n",
       "   \n",
       "           [[-0.4307, -1.6575,  1.0930,  ..., -0.9453,  1.2401,  0.4688],\n",
       "            [ 0.6306, -1.1842,  1.6672,  ..., -1.1414,  1.1467,  0.0170],\n",
       "            [ 0.4150, -1.0506,  1.6902,  ..., -0.9869,  0.9850,  0.3517],\n",
       "            ...,\n",
       "            [ 0.4409, -1.2274,  0.3408,  ..., -0.9345,  0.9570,  0.4803],\n",
       "            [ 0.0034, -2.0462,  1.0492,  ..., -0.6966,  0.7304,  0.3059],\n",
       "            [-0.5293, -2.0542,  1.6363,  ..., -0.8371,  0.6545,  0.3443]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[-0.5005, -1.6495,  1.0666,  ..., -0.9350,  1.2203,  0.4519],\n",
       "            [ 0.4279, -1.3281,  1.8969,  ..., -1.1671,  1.1410, -0.0099],\n",
       "            [ 0.3442, -1.0419,  1.6592,  ..., -0.9795,  0.9676,  0.3331],\n",
       "            ...,\n",
       "            [ 0.3596, -1.2159,  0.3160,  ..., -0.9190,  0.9447,  0.4466],\n",
       "            [-0.0771, -2.0266,  1.0212,  ..., -0.6810,  0.7199,  0.2737],\n",
       "            [-0.6847, -2.0753,  1.3762,  ..., -1.1081,  0.9753,  0.5851]],\n",
       "   \n",
       "           [[-0.4664, -1.6290,  1.0827,  ..., -0.9357,  1.2570,  0.4713],\n",
       "            [ 0.4465, -0.9696,  1.4882,  ..., -1.4151,  1.0860,  0.0271],\n",
       "            [ 0.3831, -1.0169,  1.6786,  ..., -0.9781,  1.0010,  0.3521],\n",
       "            ...,\n",
       "            [ 0.5035, -1.3910,  0.6414,  ..., -0.7106,  0.5937,  0.2487],\n",
       "            [-0.0368, -2.0145,  1.0436,  ..., -0.6853,  0.7386,  0.3056],\n",
       "            [-0.6201, -1.8781,  1.4162,  ..., -1.0523,  0.8955,  0.4904]],\n",
       "   \n",
       "           [[-0.3988, -1.6895,  1.1046,  ..., -0.9297,  1.2599,  0.4596],\n",
       "            [ 0.6560, -1.2086,  1.6815,  ..., -1.1264,  1.1652,  0.0072],\n",
       "            [ 0.4446, -1.0721,  1.7044,  ..., -0.9738,  1.0032,  0.3453],\n",
       "            ...,\n",
       "            [ 0.5688, -1.4449,  0.6656,  ..., -0.7059,  0.6103,  0.2435],\n",
       "            [ 0.0542, -1.9372,  1.1685,  ..., -1.0904,  0.7298,  0.4094],\n",
       "            [-0.5551, -1.9315,  1.4403,  ..., -1.0490,  0.9064,  0.4777]]],\n",
       "          device='cuda:0', grad_fn=<AddcmulBackward>)]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_acc(input:Tensor, t1:Tensor, t2:Tensor)->Rank0Tensor:\n",
    "    n = t1.shape[0]\n",
    "    input = input[0].argmax(dim=-1).view(n,-1)\n",
    "    t1 = t1.view(n,-1)\n",
    "    mask = t1 != vocab.pad_idx\n",
    "    return (input[mask]==t1[mask]).float().mean()\n",
    "\n",
    "def ns_acc(input:Tensor, t1:Tensor, t2:Tensor)->Rank0Tensor:\n",
    "    return accuracy(input[1], t2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics = [mask_acc, ns_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.0582905, tensor(0.0147), tensor(0.0989)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find()\n",
    "# learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mask_acc</th>\n",
       "      <th>ns_acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.212763</td>\n",
       "      <td>4.351722</td>\n",
       "      <td>0.246400</td>\n",
       "      <td>0.366042</td>\n",
       "      <td>01:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.137580</td>\n",
       "      <td>4.078460</td>\n",
       "      <td>0.278793</td>\n",
       "      <td>0.398475</td>\n",
       "      <td>01:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.940586</td>\n",
       "      <td>3.869962</td>\n",
       "      <td>0.314668</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>01:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(3, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertHead(\n",
       "  (embed): TransformerEmbedding(\n",
       "    (embed): Embedding(274, 256)\n",
       "    (pos_enc): PositionalEncoding()\n",
       "    (drop): Dropout(p=0.0)\n",
       "  )\n",
       "  (encoder): MusicTransformer(\n",
       "    (encoder): Embedding(274, 256)\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mask_decoder): MusicLinearDecoder(\n",
       "    (decoder): Linear(in_features=256, out_features=274, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "  (ns_decoder): MusicLinearDecoder(\n",
       "    (decoder): Linear(in_features=256, out_features=4, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "  (s2s_decoder): S2SDecoder(\n",
       "    (decoder): ModuleList(\n",
       "      (0): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): MusicLinearDecoder(\n",
       "      (decoder): Linear(in_features=256, out_features=274, bias=False)\n",
       "      (output_dp): RNNDropout()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
