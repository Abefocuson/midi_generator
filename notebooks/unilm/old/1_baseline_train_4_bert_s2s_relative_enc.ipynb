{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastai.text import *\n",
    "from enum import Enum\n",
    "import torch\n",
    "from fastai.text.models.awd_lstm import *\n",
    "from fastai.text.models.transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(edgeitems=10, threshold=40, linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../')\n",
    "from src.fastai_data import *\n",
    "from src.encode_data import *\n",
    "from src.serve import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lmnp_transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../../data/midi/v15/piano_duet/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Stream Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ctx_len': 150,\n",
       " 'n_layers': 16,\n",
       " 'n_heads': 8,\n",
       " 'd_model': 256,\n",
       " 'd_head': 32,\n",
       " 'd_inner': 2048,\n",
       " 'resid_p': 0.1,\n",
       " 'attn_p': 0.1,\n",
       " 'ff_p': 0.1,\n",
       " 'embed_p': 0.1,\n",
       " 'output_p': 0.1,\n",
       " 'bias': False,\n",
       " 'scale': True,\n",
       " 'act': <Activation.GeLU: 3>,\n",
       " 'double_drop': True,\n",
       " 'tie_weights': True,\n",
       " 'out_bias': True,\n",
       " 'init': <function fastai.text.models.transformer.init_transformer(m)>,\n",
       " 'mem_len': 512,\n",
       " 'mask': True,\n",
       " 'pad_idx': 1,\n",
       " 'bos_idx': 0,\n",
       " 'sep_idx': 8,\n",
       " 'transpose_range': (0, 12),\n",
       " 'note_range': (9, 138),\n",
       " 'bs': 16,\n",
       " 'bptt': 256,\n",
       " 'vocab_size': 274}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = v15s_config(vocab); config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fastai Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_tfms = [mask_tfm, next_sentence_tfm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLTFMS: [<function mask_tfm at 0x7fd8e13157b8>, <function next_sentence_tfm at 0x7fd8e1315730>]\n"
     ]
    }
   ],
   "source": [
    "data = load_music_data(path, cache_name='tmp/sample', vocab=vocab, y_offset=0, dl_tfms=dl_tfms, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb,yb = data.one_batch(cpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[155,  68, 155,  ...,   8, 147,  52],\n",
       "        [  4,  68, 155,  ...,   8,   4,  53],\n",
       "        [155,  73, 155,  ...,   8, 147,  52],\n",
       "        ...,\n",
       "        [  4,  71, 155,  ...,   8, 147,  52],\n",
       "        [155,  68, 155,  ...,   8, 147,  52],\n",
       "        [  4,  73,   4,  ...,   8, 147,   4]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[  1,   1,   1,  ...,   1,   1,   1],\n",
       "         [155,   1,   1,  ...,   1, 147,   1],\n",
       "         [  1,   1,   1,  ...,   1,   1,   1],\n",
       "         ...,\n",
       "         [155,   1,   1,  ...,   1,   1,   1],\n",
       "         [  1,   1,   1,  ...,   1,   1,   1],\n",
       "         [155,   1, 155,  ...,   1,   1,  47]], device='cuda:0'),\n",
       " tensor([[0, 0, 0,  ..., 2, 2, 2],\n",
       "         [0, 0, 0,  ..., 2, 2, 2],\n",
       "         [0, 0, 0,  ..., 2, 2, 2],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 2, 2, 2],\n",
       "         [0, 0, 0,  ..., 2, 2, 2],\n",
       "         [0, 0, 0,  ..., 2, 2, 2]], device='cuda:0')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LMNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_len = 0\n",
    "# x_len = 16 # bptt\n",
    "# seq_len = m_len+x_len\n",
    "# torch.triu(torch.ones(x_len, seq_len), diagonal=m_len).byte()[None,None].cpu().numpy()\n",
    "# torch.triu(torch.ones(x_len, seq_len), diagonal=m_len+1).byte()[None,None].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEmbedding(nn.Module):\n",
    "    \"Embedding + positional encoding + dropout\"\n",
    "    def __init__(self, vocab_sz:int, emb_sz:int, inp_p:float=0.):\n",
    "        super().__init__()\n",
    "        self.emb_sz = emb_sz\n",
    "        self.embed = embedding(vocab_sz, emb_sz)\n",
    "        self.pos_enc = PositionalEncoding(emb_sz)\n",
    "        self.drop = nn.Dropout(inp_p)\n",
    "    \n",
    "    def forward(self, inp): \n",
    "        pos = torch.arange(0, inp.size(1), device=inp.device).float()\n",
    "        return self.drop(self.embed(inp) * math.sqrt(self.emb_sz) + self.pos_enc(pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicTransformer(nn.Module):\n",
    "    \"TransformerXL model: https://arxiv.org/abs/1901.02860.\"\n",
    "    def __init__(self, vocab_sz:int, ctx_len:int, n_layers:int, n_heads:int, d_model:int, d_head:int, d_inner:int, \n",
    "                 resid_p:float=0., attn_p:float=0., ff_p:float=0., embed_p:float=0., bias:bool=False, scale:bool=True,\n",
    "                 act:Activation=Activation.ReLU, double_drop:bool=True, attn_cls:Callable=MultiHeadRelativeAttention,\n",
    "                 learned_pos_enc:bool=False, mask:bool=True, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Embedding(vocab_sz, d_model)\n",
    "        self.pos_enc = nn.Embedding(ctx_len, d_model) if learned_pos_enc else PositionalEncoding(d_model)\n",
    "        self.drop_emb = nn.Dropout(embed_p)\n",
    "        self.u = nn.Parameter(torch.Tensor(n_heads, 1, d_head)) #Remove 1 for einsum implementation of attention\n",
    "        self.v = nn.Parameter(torch.Tensor(n_heads, 1, d_head)) #Remove 1 for einsum implementation of attention\n",
    "        self.n_layers,self.d_model,self.mask = n_layers,d_model,mask\n",
    "        self.layers = nn.ModuleList([DecoderLayer(n_heads, d_model, d_head, d_inner, resid_p=resid_p, attn_p=attn_p,\n",
    "                      ff_p=ff_p, bias=bias, scale=scale, act=act, double_drop=double_drop, \n",
    "                      attn_cls=attn_cls) for k in range(n_layers)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs,x_len = x.size()\n",
    "        inp = self.drop_emb(self.encoder(x)) #.mul_(self.d_model ** 0.5)\n",
    "\n",
    "        mask = window_mask(x_len, x.device) if self.mask else None\n",
    "        #[None,:,:None] for einsum implementation of attention\n",
    "        pos = torch.arange(x_len-1, -1, -1, device=inp.device, dtype=inp.dtype)\n",
    "        pos_enc = self.pos_enc(pos)\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            inp = layer(inp, r=pos_enc, u=self.u, v=self.v, mask=mask, mem=None)\n",
    "        core_out = inp[:,-x_len:]\n",
    "        return [core_out],[core_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MusicTransformer(nn.Module):\n",
    "#     \"Transformer model: https://arxiv.org/abs/1706.03762.\"\n",
    "#     def __init__(self, embed:nn.Module, n_layers:int, n_heads:int, d_model:int, d_head:int, d_inner:int, \n",
    "#                  resid_p:float=0., attn_p:float=0., ff_p:float=0., bias:bool=True, scale:bool=True,\n",
    "#                  act:Activation=Activation.ReLU, double_drop:bool=True, attn_cls:Callable=MultiHeadAttention,\n",
    "#                  mask:bool=True, **kwargs):\n",
    "#         super().__init__()\n",
    "#         self.mask = mask\n",
    "#         self.encoder = embed\n",
    "#         self.layers = nn.ModuleList([DecoderLayer(n_heads, d_model, d_head, d_inner, resid_p=resid_p, attn_p=attn_p,\n",
    "#                       ff_p=ff_p, bias=bias, scale=scale, act=act, double_drop=double_drop, \n",
    "#                       attn_cls=attn_cls) for k in range(n_layers)])\n",
    "    \n",
    "#     def reset(self): pass\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         bs, x_len, _ = x.size()\n",
    "#         mask = window_mask(x_len, x.device) if self.mask else None\n",
    "# #         mask = torch.triu(torch.(x_len, x_len), diagonal=1).byte()[None,None] if self.mask else None\n",
    "#         #[None,:,:None] for einsum implementation of attention\n",
    "#         for layer in self.layers: x = layer(x, mask=mask)\n",
    "#         return ([x],[x]) #For the LinearDecoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.model[0].layers[0].mhra.residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.learner import _model_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['mem_len'] = 0\n",
    "config['mask'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "_model_meta[MusicTransformer] = _model_meta[TransformerXL]\n",
    "_model_meta[MusicTransformer]['config_lm'] = config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ctx_len': 150,\n",
       " 'n_layers': 16,\n",
       " 'n_heads': 8,\n",
       " 'd_model': 256,\n",
       " 'd_head': 32,\n",
       " 'd_inner': 2048,\n",
       " 'resid_p': 0.0,\n",
       " 'attn_p': 0.0,\n",
       " 'ff_p': 0.0,\n",
       " 'embed_p': 0.0,\n",
       " 'output_p': 0.0,\n",
       " 'bias': False,\n",
       " 'scale': True,\n",
       " 'act': <Activation.GeLU: 3>,\n",
       " 'double_drop': True,\n",
       " 'tie_weights': True,\n",
       " 'out_bias': True,\n",
       " 'init': <function fastai.text.models.transformer.init_transformer(m)>,\n",
       " 'mem_len': 0,\n",
       " 'mask': False,\n",
       " 'pad_idx': 1,\n",
       " 'bos_idx': 0,\n",
       " 'sep_idx': 8,\n",
       " 'transpose_range': (0, 12),\n",
       " 'note_range': (9, 138),\n",
       " 'bs': 16,\n",
       " 'bptt': 256,\n",
       " 'vocab_size': 274}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertHead(nn.Module):\n",
    "    def __init__(self, embed, encoder, mask_decoder, ns_decoder, s2s_decoder):\n",
    "        super().__init__()\n",
    "        self.embed = embed\n",
    "        self.encoder = encoder\n",
    "        self.mask_decoder = mask_decoder\n",
    "        self.ns_decoder = ns_decoder\n",
    "        self.s2s_decoder = s2s_decoder\n",
    "        \n",
    "    def forward(self, x, y=None):\n",
    "#         x_emb = self.embed(x)\n",
    "        x_enc = self.encoder(x)\n",
    "        \n",
    "        if y is None: # mask, and next sentence task\n",
    "            return self.mask_decoder(x_enc), self.ns_decoder(x_enc)\n",
    "        \n",
    "        y_emb = self.embed(y)\n",
    "        return self.mask_decoder(x_enc), self.s2s_decoder(x_enc, y_emb)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return [self.encoder, self.mask_decoder, self.ns_decoder, self.s2s_decoder][idx]\n",
    "        \n",
    "    \"A sequential module that passes the reset call to its children.\"\n",
    "    def reset(self): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S2SDecoderBlock(nn.Module):\n",
    "    \"Decoder block of a Transformer model.\"\n",
    "    #Can't use Sequential directly cause more than one input...\n",
    "    def __init__(self, n_heads:int, d_model:int, d_head:int, d_inner:int, resid_p:float=0., attn_p:float=0., ff_p:float=0.,\n",
    "                 bias:bool=True, scale:bool=True, double_drop:bool=True, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha1 = MultiHeadAttention(n_heads, d_model, d_head, resid_p=resid_p, attn_p=attn_p, bias=bias, scale=scale)\n",
    "        self.mha2 = MultiHeadAttention(n_heads, d_model, d_head, resid_p=resid_p, attn_p=attn_p, bias=bias, scale=scale)\n",
    "        self.ff   = feed_forward(d_model, d_inner, ff_p=ff_p, double_drop=double_drop)\n",
    "    \n",
    "    def forward(self, x:Tensor, enc:Tensor, mask_in:Tensor=None, mask_out:Tensor=None): \n",
    "        y = self.mha1(x, x, x, mask_out)\n",
    "        return self.ff(self.mha2(y, enc, enc, mask=mask_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_mask(x_len, device, m_len=0, size=(1,1)):\n",
    "    mem_mask = np.zeros((x_len,m_len))\n",
    "    tri_mask = np.triu(np.ones((x_len//win_size+1,x_len//win_size+1)),k=k)\n",
    "    window_mask = tri_mask.repeat(win_size,axis=0).repeat(win_size,axis=1)[:x_len,:x_len]\n",
    "    np_mask = np.concatenate((mem_mask, window_mask), axis=1)\n",
    "    mask = torch.tensor(np_mask, device=device).byte()[None,None]\n",
    "    return mask\n",
    "    \n",
    "def rand_window_mask(x_len,m_len,device,max_size=3,p=0.2,is_eval=False):\n",
    "    if is_eval or m_len == 0 or np.random.rand() >= p: \n",
    "        win_size,k = (1,1)\n",
    "    else: win_size,k = (np.random.randint(0,max_size)+1,0)\n",
    "    return window_mask(x_len, device, m_len, size=(win_size,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_mask(inp, pad_idx:int=1):\n",
    "    return torch.triu(inp.new_ones(inp.size(1),inp.size(1)), diagonal=1)[None,None].byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S2SDecoder(nn.Module):\n",
    "    def __init__(self, embed, n_hid, vocab_sz, n_layers, **kwargs):\n",
    "        super().__init__()\n",
    "        self.decoder = nn.ModuleList([S2SDecoderBlock(**kwargs) for _ in range(n_layers)])\n",
    "        self.head = MusicLinearDecoder(n_hid, vocab_sz, tie_encoder=embed, **kwargs)\n",
    "        \n",
    "#         self.pad_idx = pad_idx\n",
    "        \n",
    "    def forward(self, inp, out):\n",
    "        x_len = inp.shape[-1]\n",
    "#         mask_out = rand_window_mask(x_len, 0, inp.device, is_eval=not self.training)\n",
    "        mask_out = window_mask(x_len, inp.device)\n",
    "    \n",
    "        out = self.embed(out)\n",
    "        for dec_block in self.decoder: out = dec_block(out, inp, mask_in, mask_out)\n",
    "        return self.head(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MusicLinearDecoder(nn.Module):\n",
    "    \"To go on top of a RNNCore module and create a Language Model.\"\n",
    "    initrange=0.1\n",
    "\n",
    "    def __init__(self, n_hid:int, n_out:int, output_p:float, tie_encoder:nn.Module=None, bias:bool=True, **kwargs):\n",
    "        super().__init__()\n",
    "        self.decoder = nn.Linear(n_hid, n_out, bias=bias)\n",
    "        self.decoder.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.output_dp = RNNDropout(output_p)\n",
    "        if bias: self.decoder.bias.data.zero_()\n",
    "        if tie_encoder: self.decoder.weight = tie_encoder.weight\n",
    "\n",
    "    def forward(self, input:Tuple[Tensor,Tensor])->Tuple[Tensor,Tensor,Tensor]:\n",
    "        raw_outputs, outputs = input\n",
    "        output = self.output_dp(outputs[-1])\n",
    "        decoded = self.decoder(output)\n",
    "        return decoded, raw_outputs, outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_music_model(vocab_sz:int, config:dict=None, drop_mult:float=1.):\n",
    "    \"Create a language model from `arch` and its `config`, maybe `pretrained`.\"\n",
    "    for k in config.keys(): \n",
    "        if k.endswith('_p'): config[k] *= drop_mult\n",
    "#     tie_weights,output_p,out_bias = map(config.pop, ['tie_weights', 'output_p', 'out_bias'])\n",
    "    tie_weights,output_p,out_bias = map(config.get, ['tie_weights', 'output_p', 'out_bias'])\n",
    "    n_hid = config['d_model']\n",
    "#     embed = TransformerEmbedding(vocab_sz, n_hid, inp_p=config['embed_p'])\n",
    "#     encoder = MusicTransformer(embed=embed.embed, **config)\n",
    "    encoder = MusicTransformer(vocab_sz, **config)\n",
    "    embed = encoder.encoder\n",
    "    mask_decoder = MusicLinearDecoder(n_hid, vocab_sz, output_p, tie_encoder=encoder.encoder, bias=out_bias)\n",
    "    ns_decoder = MusicLinearDecoder(n_hid, 4, output_p, tie_encoder=None, bias=out_bias)\n",
    "    s2s_decoder = S2SDecoder(encoder.encoder, n_hid, vocab_sz, **config)\n",
    "    model = BertHead(embed, encoder, mask_decoder, ns_decoder, s2s_decoder)\n",
    "    return model.apply(init_transformer)\n",
    "\n",
    "\n",
    "def music_model_learner(data:DataBunch, config:dict=None, drop_mult:float=1., pretrained:bool=False,\n",
    "                        pretrained_fnames:OptStrTuple=None, **learn_kwargs) -> 'LanguageLearner':\n",
    "    \"Create a `Learner` with a language model from `data` and `arch`.\"\n",
    "    model = get_music_model(config['vocab_size'], config=config, drop_mult=drop_mult)\n",
    "    \n",
    "    meta = _model_meta[TransformerXL]\n",
    "    learn = MusicLearner(data, model, split_func=meta['split_lm'], \n",
    "                         bos_idx=config['bos_idx'], sep_idx=config['sep_idx'],\n",
    "                        **learn_kwargs)\n",
    "    \n",
    "    if pretrained:\n",
    "        if 'url' not in meta: \n",
    "            warn(\"There are no pretrained weights for that architecture yet!\")\n",
    "            return learn\n",
    "        model_path = untar_data(meta['url'], data=False)\n",
    "        fnames = [list(model_path.glob(f'*.{ext}'))[0] for ext in ['pth', 'pkl']]\n",
    "        learn.load_pretrained(*fnames)\n",
    "        learn.freeze()\n",
    "    if pretrained_fnames is not None:\n",
    "        fnames = [learn.path/learn.model_dir/f'{fn}.{ext}' for fn,ext in zip(pretrained_fnames, ['pth', 'pkl'])]\n",
    "        learn.load_pretrained(*fnames)\n",
    "        learn.freeze()\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sep_idx: 8\n"
     ]
    }
   ],
   "source": [
    "learn = music_model_learner(data, config, drop_mult=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb,yb = data.one_batch(cpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLoss():\n",
    "    def __init__(self, mask_loss, sent_loss):\n",
    "        self.mask_loss = mask_loss\n",
    "        self.sent_loss = sent_loss\n",
    "        \n",
    "    def __call__(self, input:Tensor, target:Tensor, target_sen:Tensor, **kwargs)->Rank0Tensor:\n",
    "        m = self.mask_loss.__call__(input[0], target, **kwargs)\n",
    "        s = self.sent_loss.__call__(input[1], target_sen, **kwargs)\n",
    "        return m + s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertTrainer(LearnerCallback):\n",
    "    \"`Callback` that regroups lr adjustment to seq_len, AR and TAR.\"\n",
    "    def __init__(self, learn:Learner):\n",
    "        super().__init__(learn)\n",
    "        \n",
    "    def on_loss_begin(self, last_output:Tuple[Tensor,Tensor,Tensor], **kwargs):\n",
    "        \"Save the extra outputs for later and only returns the true output.\"\n",
    "        return {'last_output': (last_output[0][0], last_output[1][0]) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(learn.callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.callbacks = [BertTrainer(learn, alpha=2, beta=1)]\n",
    "learn.callbacks = [BertTrainer(learn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func = BertLoss(CrossEntropyFlat(ignore_index=vocab.pad_idx), CrossEntropyFlat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 256])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[[ 2.2827e-01, -9.0823e-04, -3.4124e-01,  ...,  3.3841e-02,\n",
       "             1.0717e-02, -1.3926e-01],\n",
       "           [ 2.4798e-01, -1.8741e-02,  9.0192e-02,  ..., -2.2166e-02,\n",
       "            -1.5353e-01,  5.3387e-02],\n",
       "           [ 2.2821e-01, -5.4073e-04, -3.4054e-01,  ...,  3.3938e-02,\n",
       "             1.0536e-02, -1.3849e-01],\n",
       "           ...,\n",
       "           [ 1.4047e-02, -4.8846e-01,  4.3676e-01,  ...,  1.1514e-01,\n",
       "             1.8666e-01,  6.2869e-01],\n",
       "           [-9.0278e-02,  3.1941e-01, -6.7940e-01,  ..., -1.2845e-01,\n",
       "            -5.1675e-01,  1.1974e-02],\n",
       "           [-5.7482e-01, -2.1032e-01, -1.1250e-01,  ...,  1.2016e-01,\n",
       "            -1.9311e-01, -9.3117e-02]],\n",
       "  \n",
       "          [[-3.9660e-01,  3.7707e-01,  4.6543e-01,  ...,  1.0489e-02,\n",
       "            -3.0226e-01,  1.1085e-01],\n",
       "           [ 2.4035e-01, -1.3446e-02,  9.6038e-02,  ..., -2.8818e-03,\n",
       "            -1.5195e-01,  6.3479e-02],\n",
       "           [-3.9621e-01,  3.7743e-01,  4.6609e-01,  ...,  9.9810e-03,\n",
       "            -3.0192e-01,  1.1095e-01],\n",
       "           ...,\n",
       "           [ 2.1951e-01,  2.4624e-03, -3.3398e-01,  ...,  4.8027e-02,\n",
       "             1.4960e-02, -1.2832e-01],\n",
       "           [-9.4641e-02,  3.2564e-01, -6.7588e-01,  ..., -1.0855e-01,\n",
       "            -5.1247e-01,  1.9830e-02],\n",
       "           [-4.7686e-01,  3.4879e-02,  2.4408e-01,  ..., -4.7815e-01,\n",
       "            -5.4862e-01, -1.5401e-01]],\n",
       "  \n",
       "          [[-3.8911e-01,  3.8817e-01,  4.6737e-01,  ..., -1.1979e-02,\n",
       "            -3.1156e-01,  9.8411e-02],\n",
       "           [-4.6921e-01,  4.2009e-02,  2.3660e-01,  ..., -5.0141e-01,\n",
       "            -5.5655e-01, -1.6575e-01],\n",
       "           [ 2.2372e-01,  7.4464e-03, -3.4375e-01,  ...,  2.8840e-02,\n",
       "             1.0269e-02, -1.3655e-01],\n",
       "           ...,\n",
       "           [ 8.3406e-03, -4.7902e-01,  4.3426e-01,  ...,  1.1299e-01,\n",
       "             1.8697e-01,  6.2816e-01],\n",
       "           [-9.3691e-02,  3.2840e-01, -6.7951e-01,  ..., -1.2816e-01,\n",
       "            -5.1387e-01,  1.0875e-02],\n",
       "           [-4.6506e-01, -3.2547e-01,  5.3228e-02,  ..., -6.1119e-02,\n",
       "            -6.0679e-01, -5.6981e-01]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-3.9044e-01,  3.8940e-01,  4.6443e-01,  ...,  9.1208e-03,\n",
       "            -3.1106e-01,  9.7094e-02],\n",
       "           [ 2.4210e-01, -5.6186e-03,  9.7893e-02,  ..., -5.1386e-03,\n",
       "            -1.5654e-01,  5.3172e-02],\n",
       "           [-3.9041e-01,  3.8958e-01,  4.6515e-01,  ...,  9.1327e-03,\n",
       "            -3.1125e-01,  9.7822e-02],\n",
       "           ...,\n",
       "           [ 1.4340e-02, -4.7415e-01,  4.4385e-01,  ...,  1.3114e-01,\n",
       "             1.8075e-01,  6.2646e-01],\n",
       "           [-9.1193e-02,  3.3300e-01, -6.7578e-01,  ..., -1.0985e-01,\n",
       "            -5.1861e-01,  9.8109e-03],\n",
       "           [-4.7339e-01,  4.4300e-02,  2.4518e-01,  ..., -4.8173e-01,\n",
       "            -5.5832e-01, -1.6453e-01]],\n",
       "  \n",
       "          [[-2.9502e-01, -6.9103e-01,  5.2494e-01,  ...,  2.0288e-01,\n",
       "             3.5454e-01, -1.2769e-01],\n",
       "           [-2.2057e-01,  4.5692e-02,  6.2376e-01,  ...,  5.5250e-01,\n",
       "            -3.9433e-03,  4.5124e-01],\n",
       "           [-3.9642e-01,  3.8325e-01,  4.6748e-01,  ...,  1.1998e-02,\n",
       "            -3.0556e-01,  1.0276e-01],\n",
       "           ...,\n",
       "           [ 1.0623e-02, -4.8146e-01,  4.4456e-01,  ...,  1.3296e-01,\n",
       "             1.8796e-01,  6.3126e-01],\n",
       "           [-9.6222e-02,  3.2819e-01, -6.7510e-01,  ..., -1.0576e-01,\n",
       "            -5.1194e-01,  1.3003e-02],\n",
       "           [-4.7465e-01,  3.9735e-02,  2.4497e-01,  ..., -4.7520e-01,\n",
       "            -5.5201e-01, -1.5967e-01]],\n",
       "  \n",
       "          [[-3.9533e-01,  3.7670e-01,  4.6697e-01,  ...,  8.9293e-03,\n",
       "            -3.0373e-01,  1.0336e-01],\n",
       "           [ 2.4069e-01, -1.6927e-02,  9.4079e-02,  ..., -6.6765e-03,\n",
       "            -1.5335e-01,  5.8099e-02],\n",
       "           [-3.9500e-01,  3.7692e-01,  4.6762e-01,  ...,  8.6732e-03,\n",
       "            -3.0343e-01,  1.0395e-01],\n",
       "           ...,\n",
       "           [ 7.8663e-03, -4.8774e-01,  4.4068e-01,  ...,  1.3154e-01,\n",
       "             1.8687e-01,  6.3217e-01],\n",
       "           [-9.5097e-02,  3.2261e-01, -6.7498e-01,  ..., -1.1228e-01,\n",
       "            -5.1227e-01,  1.3694e-02],\n",
       "           [-4.7549e-01,  3.4564e-02,  2.4191e-01,  ..., -4.8107e-01,\n",
       "            -5.5188e-01, -1.6094e-01]]], device='cuda:0', grad_fn=<AddBackward0>),\n",
       "  [tensor([[[ 0.4081,  0.1919,  0.4558,  ...,  0.0366, -0.0376, -1.4012],\n",
       "            [ 1.7753, -0.0505,  0.7360,  ...,  0.0954,  0.4499,  0.0230],\n",
       "            [ 0.4056,  0.1925,  0.4543,  ...,  0.0376, -0.0371, -1.4042],\n",
       "            ...,\n",
       "            [-1.2813, -0.7006,  1.1353,  ...,  0.9347,  1.1402,  0.1275],\n",
       "            [ 0.7015, -0.8878,  0.8733,  ..., -0.9627,  2.1011, -1.1467],\n",
       "            [ 1.2494, -0.6921, -1.2299,  ..., -0.2855, -0.6618, -0.2751]],\n",
       "   \n",
       "           [[ 1.6152,  0.5724, -1.2062,  ..., -0.6686,  0.7503, -0.5617],\n",
       "            [ 1.8221, -0.0497,  0.7578,  ...,  0.1240,  0.4369,  0.0411],\n",
       "            [ 1.6130,  0.5741, -1.2077,  ..., -0.6687,  0.7508, -0.5624],\n",
       "            ...,\n",
       "            [ 0.4679,  0.1879,  0.4795,  ...,  0.0690, -0.0627, -1.3911],\n",
       "            [ 0.7668, -0.8915,  0.8901,  ..., -0.9376,  2.0973, -1.1267],\n",
       "            [-0.9543,  1.1872, -1.9490,  ...,  0.7634,  0.1769, -0.4696]],\n",
       "   \n",
       "           [[ 1.5867,  0.5622, -1.2311,  ..., -0.6955,  0.7252, -0.6246],\n",
       "            [-1.0077,  1.1774, -1.9677,  ...,  0.7323,  0.1608, -0.5344],\n",
       "            [ 0.4296,  0.1584,  0.4540,  ...,  0.0395, -0.0752, -1.4363],\n",
       "            ...,\n",
       "            [-1.2579, -0.7154,  1.1398,  ...,  0.9298,  1.0926,  0.0911],\n",
       "            [ 0.7293, -0.9065,  0.8752,  ..., -0.9580,  2.0648, -1.1790],\n",
       "            [-0.2965, -0.4099,  0.0910,  ...,  0.4953,  0.5765, -1.2219]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[ 1.6249,  0.5599, -1.1993,  ..., -0.6793,  0.7137, -0.5524],\n",
       "            [ 1.8352, -0.0522,  0.7654,  ...,  0.1159,  0.3969,  0.0421],\n",
       "            [ 1.6231,  0.5610, -1.1988,  ..., -0.6796,  0.7119, -0.5528],\n",
       "            ...,\n",
       "            [-1.2174, -0.7139,  1.1681,  ...,  0.9691,  1.0926,  0.1599],\n",
       "            [ 0.7821, -0.8981,  0.8941,  ..., -0.9367,  2.0594, -1.1228],\n",
       "            [-0.9421,  1.1867, -1.9419,  ...,  0.7603,  0.1440, -0.4608]],\n",
       "   \n",
       "           [[ 0.6294, -1.5611,  1.4192,  ...,  0.1085,  0.9276,  0.8046],\n",
       "            [ 0.6102,  0.8267, -0.4424,  ...,  0.6964, -1.1859, -0.8259],\n",
       "            [ 1.6128,  0.5806, -1.2032,  ..., -0.6838,  0.7377, -0.5873],\n",
       "            ...,\n",
       "            [-1.2341, -0.6927,  1.1661,  ...,  0.9726,  1.1183,  0.1283],\n",
       "            [ 0.7595, -0.8823,  0.8971,  ..., -0.9432,  2.0842, -1.1557],\n",
       "            [-0.9592,  1.1945, -1.9376,  ...,  0.7560,  0.1676, -0.4910]],\n",
       "   \n",
       "           [[ 1.6161,  0.5588, -1.2027,  ..., -0.6840,  0.7383, -0.5564],\n",
       "            [ 1.8257, -0.0623,  0.7676,  ...,  0.1066,  0.4222,  0.0456],\n",
       "            [ 1.6141,  0.5605, -1.2008,  ..., -0.6862,  0.7389, -0.5578],\n",
       "            ...,\n",
       "            [-1.2247, -0.7136,  1.1647,  ...,  0.9594,  1.1111,  0.1542],\n",
       "            [ 0.7621, -0.9035,  0.8998,  ..., -0.9489,  2.0782, -1.1222],\n",
       "            [-0.9626,  1.1771, -1.9444,  ...,  0.7473,  0.1673, -0.4633]]],\n",
       "          device='cuda:0', grad_fn=<SliceBackward>)],\n",
       "  [tensor([[[ 0.4081,  0.1919,  0.4558,  ...,  0.0366, -0.0376, -1.4012],\n",
       "            [ 1.7753, -0.0505,  0.7360,  ...,  0.0954,  0.4499,  0.0230],\n",
       "            [ 0.4056,  0.1925,  0.4543,  ...,  0.0376, -0.0371, -1.4042],\n",
       "            ...,\n",
       "            [-1.2813, -0.7006,  1.1353,  ...,  0.9347,  1.1402,  0.1275],\n",
       "            [ 0.7015, -0.8878,  0.8733,  ..., -0.9627,  2.1011, -1.1467],\n",
       "            [ 1.2494, -0.6921, -1.2299,  ..., -0.2855, -0.6618, -0.2751]],\n",
       "   \n",
       "           [[ 1.6152,  0.5724, -1.2062,  ..., -0.6686,  0.7503, -0.5617],\n",
       "            [ 1.8221, -0.0497,  0.7578,  ...,  0.1240,  0.4369,  0.0411],\n",
       "            [ 1.6130,  0.5741, -1.2077,  ..., -0.6687,  0.7508, -0.5624],\n",
       "            ...,\n",
       "            [ 0.4679,  0.1879,  0.4795,  ...,  0.0690, -0.0627, -1.3911],\n",
       "            [ 0.7668, -0.8915,  0.8901,  ..., -0.9376,  2.0973, -1.1267],\n",
       "            [-0.9543,  1.1872, -1.9490,  ...,  0.7634,  0.1769, -0.4696]],\n",
       "   \n",
       "           [[ 1.5867,  0.5622, -1.2311,  ..., -0.6955,  0.7252, -0.6246],\n",
       "            [-1.0077,  1.1774, -1.9677,  ...,  0.7323,  0.1608, -0.5344],\n",
       "            [ 0.4296,  0.1584,  0.4540,  ...,  0.0395, -0.0752, -1.4363],\n",
       "            ...,\n",
       "            [-1.2579, -0.7154,  1.1398,  ...,  0.9298,  1.0926,  0.0911],\n",
       "            [ 0.7293, -0.9065,  0.8752,  ..., -0.9580,  2.0648, -1.1790],\n",
       "            [-0.2965, -0.4099,  0.0910,  ...,  0.4953,  0.5765, -1.2219]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[ 1.6249,  0.5599, -1.1993,  ..., -0.6793,  0.7137, -0.5524],\n",
       "            [ 1.8352, -0.0522,  0.7654,  ...,  0.1159,  0.3969,  0.0421],\n",
       "            [ 1.6231,  0.5610, -1.1988,  ..., -0.6796,  0.7119, -0.5528],\n",
       "            ...,\n",
       "            [-1.2174, -0.7139,  1.1681,  ...,  0.9691,  1.0926,  0.1599],\n",
       "            [ 0.7821, -0.8981,  0.8941,  ..., -0.9367,  2.0594, -1.1228],\n",
       "            [-0.9421,  1.1867, -1.9419,  ...,  0.7603,  0.1440, -0.4608]],\n",
       "   \n",
       "           [[ 0.6294, -1.5611,  1.4192,  ...,  0.1085,  0.9276,  0.8046],\n",
       "            [ 0.6102,  0.8267, -0.4424,  ...,  0.6964, -1.1859, -0.8259],\n",
       "            [ 1.6128,  0.5806, -1.2032,  ..., -0.6838,  0.7377, -0.5873],\n",
       "            ...,\n",
       "            [-1.2341, -0.6927,  1.1661,  ...,  0.9726,  1.1183,  0.1283],\n",
       "            [ 0.7595, -0.8823,  0.8971,  ..., -0.9432,  2.0842, -1.1557],\n",
       "            [-0.9592,  1.1945, -1.9376,  ...,  0.7560,  0.1676, -0.4910]],\n",
       "   \n",
       "           [[ 1.6161,  0.5588, -1.2027,  ..., -0.6840,  0.7383, -0.5564],\n",
       "            [ 1.8257, -0.0623,  0.7676,  ...,  0.1066,  0.4222,  0.0456],\n",
       "            [ 1.6141,  0.5605, -1.2008,  ..., -0.6862,  0.7389, -0.5578],\n",
       "            ...,\n",
       "            [-1.2247, -0.7136,  1.1647,  ...,  0.9594,  1.1111,  0.1542],\n",
       "            [ 0.7621, -0.9035,  0.8998,  ..., -0.9489,  2.0782, -1.1222],\n",
       "            [-0.9626,  1.1771, -1.9444,  ...,  0.7473,  0.1673, -0.4633]]],\n",
       "          device='cuda:0', grad_fn=<SliceBackward>)]),\n",
       " (tensor([[[-0.0150,  0.0076,  0.1392,  0.2322],\n",
       "           [-0.5125, -0.7927,  0.2924, -0.1568],\n",
       "           [-0.0149,  0.0084,  0.1389,  0.2316],\n",
       "           ...,\n",
       "           [-0.0579, -0.4114, -0.3120, -0.0605],\n",
       "           [-0.0903, -0.3164, -0.3291, -0.0505],\n",
       "           [-0.6847,  0.1888, -0.4265, -0.7520]],\n",
       "  \n",
       "          [[ 0.3946, -0.0142, -0.1206, -0.7255],\n",
       "           [-0.5128, -0.7904,  0.2885, -0.1531],\n",
       "           [ 0.3944, -0.0132, -0.1204, -0.7253],\n",
       "           ...,\n",
       "           [-0.0158,  0.0066,  0.1342,  0.2366],\n",
       "           [-0.0889, -0.3174, -0.3287, -0.0424],\n",
       "           [-0.2532,  0.1711,  0.3620, -0.7111]],\n",
       "  \n",
       "          [[ 0.3908, -0.0108, -0.1124, -0.7293],\n",
       "           [-0.2575,  0.1760,  0.3661, -0.7042],\n",
       "           [-0.0207,  0.0126,  0.1387,  0.2359],\n",
       "           ...,\n",
       "           [-0.0599, -0.4090, -0.3061, -0.0555],\n",
       "           [-0.0904, -0.3135, -0.3241, -0.0479],\n",
       "           [ 0.0173,  0.8044, -0.6553,  0.5328]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 0.3845, -0.0189, -0.1152, -0.7186],\n",
       "           [-0.5214, -0.7984,  0.2928, -0.1485],\n",
       "           [ 0.3850, -0.0182, -0.1153, -0.7183],\n",
       "           ...,\n",
       "           [-0.0661, -0.4116, -0.3079, -0.0539],\n",
       "           [-0.0986, -0.3235, -0.3224, -0.0390],\n",
       "           [-0.2650,  0.1685,  0.3664, -0.7083]],\n",
       "  \n",
       "          [[ 0.0327, -0.0424,  0.0133, -0.3915],\n",
       "           [ 0.0615,  0.1966, -0.2877, -0.1554],\n",
       "           [ 0.3911, -0.0168, -0.1157, -0.7240],\n",
       "           ...,\n",
       "           [-0.0611, -0.4083, -0.3118, -0.0570],\n",
       "           [-0.0911, -0.3219, -0.3265, -0.0392],\n",
       "           [-0.2582,  0.1689,  0.3640, -0.7076]],\n",
       "  \n",
       "          [[ 0.3907, -0.0218, -0.1208, -0.7329],\n",
       "           [-0.5156, -0.7977,  0.2863, -0.1576],\n",
       "           [ 0.3903, -0.0212, -0.1209, -0.7323],\n",
       "           ...,\n",
       "           [-0.0607, -0.4136, -0.3165, -0.0613],\n",
       "           [-0.0929, -0.3227, -0.3314, -0.0496],\n",
       "           [-0.2574,  0.1647,  0.3599, -0.7175]]], device='cuda:0',\n",
       "         grad_fn=<AddBackward0>),\n",
       "  [tensor([[[ 0.4081,  0.1919,  0.4558,  ...,  0.0366, -0.0376, -1.4012],\n",
       "            [ 1.7753, -0.0505,  0.7360,  ...,  0.0954,  0.4499,  0.0230],\n",
       "            [ 0.4056,  0.1925,  0.4543,  ...,  0.0376, -0.0371, -1.4042],\n",
       "            ...,\n",
       "            [-1.2813, -0.7006,  1.1353,  ...,  0.9347,  1.1402,  0.1275],\n",
       "            [ 0.7015, -0.8878,  0.8733,  ..., -0.9627,  2.1011, -1.1467],\n",
       "            [ 1.2494, -0.6921, -1.2299,  ..., -0.2855, -0.6618, -0.2751]],\n",
       "   \n",
       "           [[ 1.6152,  0.5724, -1.2062,  ..., -0.6686,  0.7503, -0.5617],\n",
       "            [ 1.8221, -0.0497,  0.7578,  ...,  0.1240,  0.4369,  0.0411],\n",
       "            [ 1.6130,  0.5741, -1.2077,  ..., -0.6687,  0.7508, -0.5624],\n",
       "            ...,\n",
       "            [ 0.4679,  0.1879,  0.4795,  ...,  0.0690, -0.0627, -1.3911],\n",
       "            [ 0.7668, -0.8915,  0.8901,  ..., -0.9376,  2.0973, -1.1267],\n",
       "            [-0.9543,  1.1872, -1.9490,  ...,  0.7634,  0.1769, -0.4696]],\n",
       "   \n",
       "           [[ 1.5867,  0.5622, -1.2311,  ..., -0.6955,  0.7252, -0.6246],\n",
       "            [-1.0077,  1.1774, -1.9677,  ...,  0.7323,  0.1608, -0.5344],\n",
       "            [ 0.4296,  0.1584,  0.4540,  ...,  0.0395, -0.0752, -1.4363],\n",
       "            ...,\n",
       "            [-1.2579, -0.7154,  1.1398,  ...,  0.9298,  1.0926,  0.0911],\n",
       "            [ 0.7293, -0.9065,  0.8752,  ..., -0.9580,  2.0648, -1.1790],\n",
       "            [-0.2965, -0.4099,  0.0910,  ...,  0.4953,  0.5765, -1.2219]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[ 1.6249,  0.5599, -1.1993,  ..., -0.6793,  0.7137, -0.5524],\n",
       "            [ 1.8352, -0.0522,  0.7654,  ...,  0.1159,  0.3969,  0.0421],\n",
       "            [ 1.6231,  0.5610, -1.1988,  ..., -0.6796,  0.7119, -0.5528],\n",
       "            ...,\n",
       "            [-1.2174, -0.7139,  1.1681,  ...,  0.9691,  1.0926,  0.1599],\n",
       "            [ 0.7821, -0.8981,  0.8941,  ..., -0.9367,  2.0594, -1.1228],\n",
       "            [-0.9421,  1.1867, -1.9419,  ...,  0.7603,  0.1440, -0.4608]],\n",
       "   \n",
       "           [[ 0.6294, -1.5611,  1.4192,  ...,  0.1085,  0.9276,  0.8046],\n",
       "            [ 0.6102,  0.8267, -0.4424,  ...,  0.6964, -1.1859, -0.8259],\n",
       "            [ 1.6128,  0.5806, -1.2032,  ..., -0.6838,  0.7377, -0.5873],\n",
       "            ...,\n",
       "            [-1.2341, -0.6927,  1.1661,  ...,  0.9726,  1.1183,  0.1283],\n",
       "            [ 0.7595, -0.8823,  0.8971,  ..., -0.9432,  2.0842, -1.1557],\n",
       "            [-0.9592,  1.1945, -1.9376,  ...,  0.7560,  0.1676, -0.4910]],\n",
       "   \n",
       "           [[ 1.6161,  0.5588, -1.2027,  ..., -0.6840,  0.7383, -0.5564],\n",
       "            [ 1.8257, -0.0623,  0.7676,  ...,  0.1066,  0.4222,  0.0456],\n",
       "            [ 1.6141,  0.5605, -1.2008,  ..., -0.6862,  0.7389, -0.5578],\n",
       "            ...,\n",
       "            [-1.2247, -0.7136,  1.1647,  ...,  0.9594,  1.1111,  0.1542],\n",
       "            [ 0.7621, -0.9035,  0.8998,  ..., -0.9489,  2.0782, -1.1222],\n",
       "            [-0.9626,  1.1771, -1.9444,  ...,  0.7473,  0.1673, -0.4633]]],\n",
       "          device='cuda:0', grad_fn=<SliceBackward>)],\n",
       "  [tensor([[[ 0.4081,  0.1919,  0.4558,  ...,  0.0366, -0.0376, -1.4012],\n",
       "            [ 1.7753, -0.0505,  0.7360,  ...,  0.0954,  0.4499,  0.0230],\n",
       "            [ 0.4056,  0.1925,  0.4543,  ...,  0.0376, -0.0371, -1.4042],\n",
       "            ...,\n",
       "            [-1.2813, -0.7006,  1.1353,  ...,  0.9347,  1.1402,  0.1275],\n",
       "            [ 0.7015, -0.8878,  0.8733,  ..., -0.9627,  2.1011, -1.1467],\n",
       "            [ 1.2494, -0.6921, -1.2299,  ..., -0.2855, -0.6618, -0.2751]],\n",
       "   \n",
       "           [[ 1.6152,  0.5724, -1.2062,  ..., -0.6686,  0.7503, -0.5617],\n",
       "            [ 1.8221, -0.0497,  0.7578,  ...,  0.1240,  0.4369,  0.0411],\n",
       "            [ 1.6130,  0.5741, -1.2077,  ..., -0.6687,  0.7508, -0.5624],\n",
       "            ...,\n",
       "            [ 0.4679,  0.1879,  0.4795,  ...,  0.0690, -0.0627, -1.3911],\n",
       "            [ 0.7668, -0.8915,  0.8901,  ..., -0.9376,  2.0973, -1.1267],\n",
       "            [-0.9543,  1.1872, -1.9490,  ...,  0.7634,  0.1769, -0.4696]],\n",
       "   \n",
       "           [[ 1.5867,  0.5622, -1.2311,  ..., -0.6955,  0.7252, -0.6246],\n",
       "            [-1.0077,  1.1774, -1.9677,  ...,  0.7323,  0.1608, -0.5344],\n",
       "            [ 0.4296,  0.1584,  0.4540,  ...,  0.0395, -0.0752, -1.4363],\n",
       "            ...,\n",
       "            [-1.2579, -0.7154,  1.1398,  ...,  0.9298,  1.0926,  0.0911],\n",
       "            [ 0.7293, -0.9065,  0.8752,  ..., -0.9580,  2.0648, -1.1790],\n",
       "            [-0.2965, -0.4099,  0.0910,  ...,  0.4953,  0.5765, -1.2219]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[ 1.6249,  0.5599, -1.1993,  ..., -0.6793,  0.7137, -0.5524],\n",
       "            [ 1.8352, -0.0522,  0.7654,  ...,  0.1159,  0.3969,  0.0421],\n",
       "            [ 1.6231,  0.5610, -1.1988,  ..., -0.6796,  0.7119, -0.5528],\n",
       "            ...,\n",
       "            [-1.2174, -0.7139,  1.1681,  ...,  0.9691,  1.0926,  0.1599],\n",
       "            [ 0.7821, -0.8981,  0.8941,  ..., -0.9367,  2.0594, -1.1228],\n",
       "            [-0.9421,  1.1867, -1.9419,  ...,  0.7603,  0.1440, -0.4608]],\n",
       "   \n",
       "           [[ 0.6294, -1.5611,  1.4192,  ...,  0.1085,  0.9276,  0.8046],\n",
       "            [ 0.6102,  0.8267, -0.4424,  ...,  0.6964, -1.1859, -0.8259],\n",
       "            [ 1.6128,  0.5806, -1.2032,  ..., -0.6838,  0.7377, -0.5873],\n",
       "            ...,\n",
       "            [-1.2341, -0.6927,  1.1661,  ...,  0.9726,  1.1183,  0.1283],\n",
       "            [ 0.7595, -0.8823,  0.8971,  ..., -0.9432,  2.0842, -1.1557],\n",
       "            [-0.9592,  1.1945, -1.9376,  ...,  0.7560,  0.1676, -0.4910]],\n",
       "   \n",
       "           [[ 1.6161,  0.5588, -1.2027,  ..., -0.6840,  0.7383, -0.5564],\n",
       "            [ 1.8257, -0.0623,  0.7676,  ...,  0.1066,  0.4222,  0.0456],\n",
       "            [ 1.6141,  0.5605, -1.2008,  ..., -0.6862,  0.7389, -0.5578],\n",
       "            ...,\n",
       "            [-1.2247, -0.7136,  1.1647,  ...,  0.9594,  1.1111,  0.1542],\n",
       "            [ 0.7621, -0.9035,  0.8998,  ..., -0.9489,  2.0782, -1.1222],\n",
       "            [-0.9626,  1.1771, -1.9444,  ...,  0.7473,  0.1673, -0.4633]]],\n",
       "          device='cuda:0', grad_fn=<SliceBackward>)]))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_acc(input:Tensor, t1:Tensor, t2:Tensor)->Rank0Tensor:\n",
    "    n = t1.shape[0]\n",
    "    input = input[0].argmax(dim=-1).view(n,-1)\n",
    "    t1 = t1.view(n,-1)\n",
    "    mask = t1 != vocab.pad_idx\n",
    "    return (input[mask]==t1[mask]).float().mean()\n",
    "\n",
    "def ns_acc(input:Tensor, t1:Tensor, t2:Tensor)->Rank0Tensor:\n",
    "    return accuracy(input[1], t2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics = [mask_acc, ns_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.0117536, tensor(0.0995), tensor(0.1782)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find()\n",
    "# learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mask_acc</th>\n",
       "      <th>ns_acc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.097771</td>\n",
       "      <td>3.068573</td>\n",
       "      <td>0.549704</td>\n",
       "      <td>0.467229</td>\n",
       "      <td>02:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.343284</td>\n",
       "      <td>2.416331</td>\n",
       "      <td>0.589760</td>\n",
       "      <td>0.501202</td>\n",
       "      <td>02:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.144423</td>\n",
       "      <td>2.243269</td>\n",
       "      <td>0.603608</td>\n",
       "      <td>0.476431</td>\n",
       "      <td>02:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(3, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertHead(\n",
       "  (embed): Embedding(274, 256)\n",
       "  (encoder): MusicTransformer(\n",
       "    (encoder): Embedding(274, 256)\n",
       "    (pos_enc): PositionalEncoding()\n",
       "    (drop_emb): Dropout(p=0.0)\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mask_decoder): MusicLinearDecoder(\n",
       "    (decoder): Linear(in_features=256, out_features=274, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "  (ns_decoder): MusicLinearDecoder(\n",
       "    (decoder): Linear(in_features=256, out_features=4, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "  (s2s_decoder): S2SDecoder(\n",
       "    (decoder): ModuleList(\n",
       "      (0): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): S2SDecoderBlock(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=256, out_features=768, bias=False)\n",
       "          (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (drop_att): Dropout(p=0.0)\n",
       "          (drop_res): Dropout(p=0.0)\n",
       "          (ln): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.0)\n",
       "            (3): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): MusicLinearDecoder(\n",
       "      (decoder): Linear(in_features=256, out_features=274, bias=False)\n",
       "      (output_dp): RNNDropout()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
