{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21\n",
    "import torch\n",
    "\n",
    "from fastai.distributed import *\n",
    "from fastai.text.models.transformer import *\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from fastai_data import *\n",
    "from lmnp_transformer import *\n",
    "from encode_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(edgeitems=10, threshold=40, linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=16\n",
    "bptt=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose_tfm = partial(rand_transpose, enc_offset=ENC_OFFSET, rand_range=(0,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data/midi/v9/midi_encode/np/shortdur/')\n",
    "data = LMNPDataBunch.load(path, bs=bs, bptt=bptt, cache_name='tmp/hook', train_tfms=[transpose_tfm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 130, 128), (1, 132, 128)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SZ = create_vocab_sizes(path/'tmp/all')\n",
    "N_COMPS = len(VOCAB_SZ)\n",
    "N_EMBS = 128\n",
    "EMB_IDXS = range(N_COMPS)\n",
    "EMB_DIM = [N_EMBS]*len(EMB_IDXS)\n",
    "EMB_MAP = list(zip(EMB_IDXS,VOCAB_SZ,EMB_DIM))\n",
    "EMB_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2embidx = { i:EMB_MAP[i] for i in range(N_COMPS) }\n",
    "total_embs = sum([v[-1] for k,v in idx2embidx.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ctx_len': 150,\n",
       " 'n_layers': 12,\n",
       " 'n_heads': 10,\n",
       " 'd_model': 256,\n",
       " 'd_head': 41,\n",
       " 'd_inner': 2100,\n",
       " 'resid_p': 0.1,\n",
       " 'attn_p': 0.1,\n",
       " 'ff_p': 0.1,\n",
       " 'embed_p': 0.1,\n",
       " 'output_p': 0.1,\n",
       " 'bias': False,\n",
       " 'scale': True,\n",
       " 'act': <Activation.ReLU: 1>,\n",
       " 'double_drop': True,\n",
       " 'tie_weights': True,\n",
       " 'out_bias': True,\n",
       " 'init': <function fastai.text.models.transformer.init_transformer(m)>,\n",
       " 'mem_len': 512,\n",
       " 'mask': True,\n",
       " 'emb_map': [(0, 130, 128), (1, 132, 128)],\n",
       " 'idx_map': {0: (0, 130, 128), 1: (1, 132, 128)},\n",
       " 'loss_weights': [1, 1],\n",
       " 'pad_idx': 0,\n",
       " 'bos_idx': 2,\n",
       " 'mask_type': <MaskType.RandomWindow: 3>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = tfmerXL_lm_config\n",
    "config['emb_map'] = list(zip(EMB_IDXS,VOCAB_SZ,EMB_DIM))\n",
    "config['idx_map'] = idx2embidx\n",
    "config['loss_weights'] = [1,1] # note,duration\n",
    "config['pad_idx'] = PADDING_IDX+ENC_OFFSET\n",
    "config['bos_idx'] = VALTBOS+ENC_OFFSET\n",
    "config['mask_type'] = MaskType.RandomWindow\n",
    "config['act'] = Activation.ReLU\n",
    "\n",
    "config['d_model'] = total_embs\n",
    "config['mem_len'] = 512\n",
    "\n",
    "config['resid_p'] = 0.1\n",
    "config['attn_p'] = 0.1 # attention dropout\n",
    "config['ff_p'] = 0.1\n",
    "config['embed_p'] = 0.1 # embedding dropout\n",
    "config['output_p'] = 0.1 # decoder dropout (before final linear layer)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data, config, clip=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = data.one_batch(cpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/midi/v9/midi_encode/np/shortdur/models/hook/1_epoch20_best.pth'),\n",
       " PosixPath('data/midi/v9/midi_encode/np/shortdur/models/hook/v9_1_epoch20_best.pth'),\n",
       " PosixPath('data/midi/v9/midi_encode/np/shortdur/models/hook/v9_2_epoch30_best.pth'),\n",
       " PosixPath('data/midi/v9/midi_encode/np/shortdur/models/hook/v9_1_epoch20.pth'),\n",
       " PosixPath('data/midi/v9/midi_encode/np/shortdur/models/hook/1_epoch20.pth'),\n",
       " PosixPath('data/midi/v9/midi_encode/np/shortdur/models/hook/v9_2_epoch30.pth')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = get_files(path/'models/hook', recurse=True); models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_path = Path('data/midi/v9/midi_encode/np/shortdur/models/pop/v9_2_epoch30_best.pth')\n",
    "load_path = Path('data/midi/v9/midi_encode/np/shortdur/models/hook/v9_2_epoch30_best.pth')\n",
    "state = torch.load(load_path, map_location='cpu')\n",
    "get_model(learn.model).load_state_dict(state['model'], strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb,yb = learn.data.one_batch(cpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_len = 60\n",
    "files = get_files(path/'hooktheory', extensions=['.npy'], recurse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/midi/v9/midi_encode/np/shortdur/hooktheory/pianoroll/j/john-denver/take-me-home-country-roads/bridge_key_cmajor.npy'),\n",
       " PosixPath('data/midi/v9/midi_encode/np/shortdur/hooktheory/pianoroll/j/john-denver/take-me-home---country-roads/chorus_key_cmajor.npy')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading from specific file\n",
    "keywords = 'country road'.split(' ')\n",
    "def contains_keywords(f): return all([k in str(f) for k in keywords])\n",
    "search = [f for f in files if contains_keywords(f)]; search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/midi/v9/midi_encode/np/shortdur/hooktheory/pianoroll/j/john-denver/take-me-home---country-roads/chorus_key_cmajor.npy')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file = np.random.choice(files)\n",
    "file = search[-1]\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#good_one = Path('data/midi/v7/midi_encode/np/hook_1bar_nopos/hooktheory/c/cool-and-new-web-comic/tick---tock/chorus.npy')\n",
    "# file = Path('data/midi/v9/midi_encode/np/shortdur/hooktheory/pianoroll/r/ritchie-valen/la-bamba/chorus_key_cmajor.npy')\n",
    "# third_eye = Path('data/midi/v7/midi_encode/np/hook_1bar_nopos/hooktheory/t/third-eye-blind/semi-charmed-life/chorus.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_np = np.load(file)\n",
    "seed_np = np.load(file)[:seed_len]\n",
    "xb = torch.tensor(seed_np)[None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out, seed = learn.predict(xb, n_words=340, temperature=1, min_p=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher temperature = More randomness (1.5)\n",
    "# Lower temperature = Less random (.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='340', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted BOS token. Returning prediction...\n"
     ]
    }
   ],
   "source": [
    "out, seed = learn.predict(xb, n_words=340, temperatures=(1.5,0.9), min_ps=(1/128,0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = npenc2stream(out)\n",
    "stream.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.show('midi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_stream = npenc2stream(seed)\n",
    "seed_stream.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_stream.show('midi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alltogether now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_output = np.concatenate((seed,out), axis=0)\n",
    "full_stream = npenc2stream(full_output)\n",
    "full_stream.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_stream.show('midi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_stream = npenc2stream(song_np)\n",
    "original_stream.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_stream.show('midi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flask App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-f1136a8e97e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflask\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mapp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "from flask import Flask, Response\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/hello/', methods=['GET', 'POST'])\n",
    "def hello_world():\n",
    "    return 'Hello, World!'\n",
    "\n",
    "@app.route('/predict')\n",
    "def predict():\n",
    "    out, seed = learn.predict(learn, xb, n_words=340, temperatures=(1.5,0.9), min_ps=(1/128,0.0))\n",
    "    \n",
    "    feature1 = request.args.get('feature1')\n",
    "    feature2 = request.args.get('feature2')\n",
    "    feature3 = request.args.get('feature3')\n",
    "    input = [feature1, feature2, feature3]\n",
    "    prediction = model.predict(input)\n",
    "    result = dict({\n",
    "        'prediction': prediction\n",
    "    })\n",
    "    return jsonify(result)\n",
    "@app.route('/health')\n",
    "def health_check():\n",
    "    return Response(\"\", status = 200)\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True,host='0.0.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
